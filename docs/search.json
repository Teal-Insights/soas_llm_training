[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "",
    "text": "Preface\nThis book accompanies the workshop AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research for SOAS College of Social Sciences. In two hours, we’ll explore how this new technology—despite its limitations—can enhance your research capabilities by handling routine tasks while you focus on critical analysis and theoretical contributions.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this workshop, you will be able to:\n\nEvaluate and select appropriate LLM tools for your research needs\nDesign effective prompts that leverage your domain expertise\nUse LLMs to enhance literature reviews and cross-disciplinary understanding\nApply LLMs for coding assistance and data analysis support\nUnderstand validation approaches for LLM-generated content\nRecognize both the transformative potential and important limitations of these tools",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#who-this-workshop-is-for",
    "href": "index.html#who-this-workshop-is-for",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Who This Workshop Is For",
    "text": "Who This Workshop Is For\nThis workshop is designed for experienced researchers who want to explore how LLMs might enhance their work. We assume you have:\n\nDeep expertise in your research domain\nHealthy skepticism about new technologies and their promises\nNo prior knowledge of LLMs or coding experience\nInterest in practical tools that could streamline routine research tasks\n\nYour skepticism is justified—LLMs have real limitations we’ll address directly. This workshop provides a realistic assessment of both capabilities and constraints.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#workshop-scope",
    "href": "index.html#workshop-scope",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Workshop Scope",
    "text": "Workshop Scope\nArtificial Intelligence is a vast and rapidly evolving field. In two hours, we can only cover a small portion of this landscape. This workshop aims to provide you with three core concepts that will equip you with immediately useful tools and a framework for continued learning:\n\nA mental model for understanding when and how to use AI effectively\nPractical techniques for common research tasks\nValidation strategies to maintain research integrity\n\n\nWhat We Will Cover\n\nConsumer-friendly LLM interfaces you can use immediately\nHands-on practice with real research applications\nIntroduction to programmatic possibilities for larger projects\nCase studies demonstrating successful academic use\n\n\n\nWhat We Will Not Cover\n\nComprehensive discussion of AI’s social implications (though we acknowledge them)\nDetailed API programming instruction\nExhaustive review of AI startup tools\nSolutions to replace human critical thinking",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#understanding-llms-in-research-context",
    "href": "index.html#understanding-llms-in-research-context",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Understanding LLMs in Research Context",
    "text": "Understanding LLMs in Research Context\nLarge Language Models represent a new category of research tool. Like any emerging technology, they come with significant limitations: training data biases, lack of contextual understanding, tendency to generate plausible-sounding but incorrect information, and important ethical considerations around consent and knowledge production.\nHowever, when used strategically and with appropriate validation, these tools can transform research workflows. By automating time-consuming routine tasks—initial literature categorization, draft translations, basic coding—LLMs free researchers to dedicate more time to what humans do best: critical analysis, theoretical development, contextual interpretation, and ethical judgment.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-your-instructor",
    "href": "index.html#about-your-instructor",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "About Your Instructor",
    "text": "About Your Instructor",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#our-two-hour-journey",
    "href": "index.html#our-two-hour-journey",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Our Two-Hour Journey",
    "text": "Our Two-Hour Journey\n\nPart 1: Foundations (20 minutes)\nUnderstanding LLMs as Research Tools\n\nThe “Jagged Frontier”: Where AI excels versus where humans remain essential\nKey concepts: model capabilities, cost structures, context windows\nWhy Google Gemini for academic work (citations, extended context, NotebookLM)\n\n\n\nPart 2: Practical Applications (70 minutes)\nHands-On Tools and Techniques\n\nPrompt engineering fundamentals with practice exercises\nCreating reusable “Gems” for common research tasks\nEnhancing literature reviews across languages and disciplines\nGetting coding assistance without programming expertise\nBrief exploration of complementary tools (Perplexity, ChatGPT, Claude)\n\n\n\nPart 3: Advanced Possibilities (15 minutes)\nScaling Your Research\n\nCase study: How I classified 18,000 Chinese overseas lending projects in 15 hours (versus 1,500 hours manually).\nValidation strategy: achieving 91.8% agreement with human raters\nEnabling policy-relevant analysis: quantifying green lending patterns across the Belt and Road Initiative\nIntroduction to programmatic approaches for large-scale research\nWhen and how to consider API-based workflows\n\n\n\nPart 4: Q&A and Discussion (15 minutes)\nYour Questions and Next Steps",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#approaching-this-material",
    "href": "index.html#approaching-this-material",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Approaching This Material",
    "text": "Approaching This Material\nThis workshop takes a pragmatic stance. We neither dismiss AI’s real limitations nor accept inflated claims about its capabilities. Instead, we focus on practical applications where LLMs demonstrably save time and enhance research capacity while maintaining academic standards.\nThroughout, we’ll use clear language and define technical terms as they arise. When we discuss “context windows,” we’ll explain this means how much text an AI can process at once. When we mention “hallucinations,” we’ll clarify this refers to AI’s tendency to generate false but plausible information.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#preparing-for-the-workshop",
    "href": "index.html#preparing-for-the-workshop",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Preparing for the Workshop",
    "text": "Preparing for the Workshop\nYou’ll need:\n\nA free Google Gemini account (setup instructions in Appendix A)\nA research question or paper you’re currently working on\nWillingness to experiment while maintaining healthy skepticism",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "How to Use This Book",
    "text": "How to Use This Book\nEach chapter provides:\n\nClear explanation of concepts without unnecessary jargon\nStep-by-step instructions with visual guides\nHands-on exercises using real research scenarios\nCommon pitfalls and how to avoid them\nValidation strategies specific to each application\n\nThis book serves as both a workshop companion and a reference for future exploration. The goal is not to make you an AI expert but to provide practical tools that enhance your existing research practice.\nLet’s begin exploring how these tools can support your important work.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  About Your Instructor",
    "section": "",
    "text": "1.1 How I Got Here\nCarlos Oya reached out after seeing a recent ODI Global paper I co-authored with Yunnan Chen called Greener on the other side? Mapping China’s overseas co-financing and financial innovation. We used a novel LLM-based approach to classify “green” Chinese lending projects—something that would have taken a large research team months to do manually.\nWhen we did this work, I looked for “best practices” for validating LLM findings. There weren’t many. So we developed our own validation method and published both a methodological appendix and our GitHub repository. It’s not perfect, but it’s something for others to build upon.\nThis experience showed me how LLMs can enhance what’s possible for policy-relevant research. Two policy researchers on a tight budget accomplished what traditionally required large, grant-funded research teams. There’s a long way to go to establish best practices for the use of LLMs in policy research, so I’m trying to do my best to move the conversation forward.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#how-i-got-here",
    "href": "intro.html#how-i-got-here",
    "title": "1  About Your Instructor",
    "section": "",
    "text": "Source: Chen & Emery 2025\n\n\n\n\n\n\n\n\n\nKey Numbers from Our Chinese Lending Project\n\n\n\n\n18,000 projects classified in 15 hours using Deepseek v3\n$1.58 total cost vs. estimated $22,500 for manual classification\n91.8% agreement with human raters on validation sample\nFirst comprehensive analysis of China’s green overseas lending portfolio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#what-i-do-now",
    "href": "intro.html#what-i-do-now",
    "title": "1  About Your Instructor",
    "section": "1.2 What I Do Now",
    "text": "1.2 What I Do Now\nDay job: Running Teal Insights, where we help Global South finance ministries navigate complex debt sustainability and climate investment challenges. We’re philanthropically funded with a mandate to build open-source tools—including LLM tools—so countries don’t have to pay exorbitant fees to financial advisors.\nOur approach: Small team (US, Nigeria, Kenya) using AI tools heavily to amplify our impact in research and code development.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#other-relevant-experience",
    "href": "intro.html#other-relevant-experience",
    "title": "1  About Your Instructor",
    "section": "1.3 Other Relevant Experience",
    "text": "1.3 Other Relevant Experience\n\nEM sovereign debt resarch analyst, Morgan Stanley Investment Management\nAdjunct Lecturer, Johns Hopkins SAIS (teaching students to do real-world data analysis on financial and sustainability data)\n\nThought leadership on sovereign debt + sustainability, World Bank\nChinese debt restructuring & flows research, AidData\nBig nerd 🤓",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#why-this-workshop",
    "href": "intro.html#why-this-workshop",
    "title": "1  About Your Instructor",
    "section": "1.4 Why This Workshop?",
    "text": "1.4 Why This Workshop?\n\n\n\n\n\n\nA Note on Expertise\n\n\n\nThis technology is very new. Nobody is really an “expert” yet. But since we’re using these tools extensively, we’ve learned hard lessons about how to use them well—and badly.\nWhen Carlos asked me to teach this, I figured it was a great excuse to organize my thoughts on something I discuss with skeptical, curious researchers all the time.\nThis is my first attempt at articulating practical guidance for academics who want to use AI responsibly. I hope it’s useful, and I invite all feedback on how to make it better.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html",
    "href": "foundations_intro.html",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "",
    "text": "2.1 Learning Objectives\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#learning-objectives",
    "href": "foundations_intro.html#learning-objectives",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "",
    "text": "Develop a mental model for understanding AI as a collaborative research tool rather than a replacement for human expertise\nUnderstand the “jagged frontier” concept and use it to predict where AI will excel versus where it will struggle\nTriage research tasks responsibly by categorizing them as human-only, collaborative, or AI-assisted based on the frontier\nRecognize AI’s key limitations (hallucination, bias, missing context) and plan accordingly\nBegin exploring your own jagged frontier through systematic experimentation with low-stakes tasks",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#why-this-matters-for-your-research",
    "href": "foundations_intro.html#why-this-matters-for-your-research",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.2 Why This Matters for Your Research",
    "text": "2.2 Why This Matters for Your Research\nBefore diving into the technical details, let’s be clear about why you might want to learn to work with AI: these tools can dramatically expand what’s possible for individual researchers and small teams. When used effectively, AI can handle routine tasks that typically consume enormous amounts of time—literature searches, initial coding, translation, summarization—freeing you to focus on what only you can do: critical analysis, theoretical development, fieldwork insights, and interpretation.\nThe researchers I know who’ve learned to work well with AI aren’t replacing their expertise; they’re amplifying it. They’re tackling more ambitious projects, exploring research questions they previously couldn’t afford the time to pursue, and spending more of their energy on the intellectually rewarding aspects of research rather than the drudgery.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#a-new-way-to-think-about-ai-collaboration",
    "href": "foundations_intro.html#a-new-way-to-think-about-ai-collaboration",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.3 A New Way to Think About AI Collaboration",
    "text": "2.3 A New Way to Think About AI Collaboration\nThink of Large Language Models not as magical oracles or human replacements, but as sophisticated research assistants with a unique set of strengths and blind spots. Ethan Mollick suggests a particularly useful analogy:\n\ntreat AI like an infinitely patient new coworker who forgets everything you tell them each new conversation, one that comes highly recommended but whose actual abilities are not that clear.\n\nThis analogy helps us understand how to work with AI effectively:\nHuman-like aspects:\n\nNew on the job: Needs clear instructions and guidance, may not understand your specific context\nCoworker relationship: Works best through collaboration and back-and-forth dialogue\n\nNon-human aspects:\n\nInfinite patience: Never gets frustrated with repetitive requests or extensive revisions\nComplete forgetfulness: Starts fresh in each conversation with no memory of previous interactions\n\nUnlike traditional software that follows predictable rules, LLMs work more like collaborating with a capable but quirky colleague who can be creative and insightful, but may also confidently present plausible-sounding information that’s completely wrong.\n\n\n\n\n\n\nBuilding on Ethan Mollick’s Work\n\n\n\nThis chapter builds heavily on the work of Ethan Mollick, particularly his concept of the “jagged frontier” and his research on human-AI collaboration. I’ve found his insights invaluable in my own journey learning to work with AI. I highly recommend reading his book Co-Intelligence and following his Substack “One Useful Thing” for deeper insights into working effectively with AI.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#the-jagged-frontier-understanding-ais-uneven-capabilities",
    "href": "foundations_intro.html#the-jagged-frontier-understanding-ais-uneven-capabilities",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.4 The Jagged Frontier: Understanding AI’s Uneven Capabilities",
    "text": "2.4 The Jagged Frontier: Understanding AI’s Uneven Capabilities\nThe most important concept for working with LLMs is what Mollick (& esteemed co-authors) calls the “jagged frontier” of AI capabilities. Imagine a fortress wall with towers and battlements jutting out at irregular points. Some parts of the wall extend far into the countryside, while others fold back toward the center. This wall represents AI’s capabilities—everything inside the wall represents tasks AI can handle well, while everything outside represents tasks where AI struggles.\n\n\n\nJagged Frontier of AI Capabilities\n\n\nThe challenge is that this wall is invisible. Tasks that seem equally difficult to humans often fall on opposite sides of the frontier. For example:\nInside the Frontier (AI excels):\n\nSummarizing academic papers and identifying key themes\nCreating first drafts of literature reviews\nTranslating research documents between major languages\nGenerating research questions and hypotheses to explore\nCoding assistance in most major languages (R, Python, STATA, etc..)\nWriting and formatting citations and bibliographies\n\nOutside the Frontier (AI struggles):\n\nGrasping context that isn’t explicitly stated\nMaking ethical judgments about research implications\nHumor. Seriously, try it. It’s all dad joke vibes\n\nThis unpredictability means you cannot assume that because AI handles one complex task well, it will handle a seemingly simpler related task with equal competence.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#what-llms-do-well-vs.-what-they-dont",
    "href": "foundations_intro.html#what-llms-do-well-vs.-what-they-dont",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.5 What LLMs Do Well vs. What They Don’t",
    "text": "2.5 What LLMs Do Well vs. What They Don’t\n\n2.5.1 AI Strengths\nScale and Speed: LLMs can process vast amounts of text in seconds. Need to identify key themes across 50 research papers? AI can help you get started in minutes rather than weeks.\nPattern Recognition: AI excels at identifying patterns across large datasets of text, finding connections you might miss, and synthesizing information from multiple sources.\nFirst-Draft Generation: Whether it’s grant applications, literature reviews, or research summaries, AI can create useful first drafts that you can then refine with your expertise.\nLanguage Tasks: Translation, summarization, and style adaptation are genuine AI strengths that can save researchers enormous amounts of time.\n\n\n2.5.2 AI Limitations\nHallucination: LLMs confidently generate plausible-sounding but false information. They might cite papers that don’t exist, create realistic-sounding statistics, or confidently state “facts” they’ve essentially made up.\n\n\n\n\n\n\nWhat is Hallucination?\n\n\n\n“Hallucination” refers to when AI generates plausible-sounding but factually incorrect information. This isn’t a bug—it’s how these models work. They predict what text should come next based on patterns, not facts. A hallucinated research paper might have a realistic title, believable authors, and a publication year that makes sense, but the paper simply doesn’t exist.\n\n\nCultural and Geographic Bias: LLMs are trained predominantly on text from wealthy countries in the Global North, often in English. They reflect the biases in that data and may default to Western-centric perspectives on development, governance, or social issues.\nMissing Context: AI only knows what’s explicitly written down. It misses the unspoken context that you understand from fieldwork—the power dynamics in a room, historical tensions between communities, or the significance of what isn’t being said.\nLack of True Understanding: When I read IMF documents, boring bureaucratic language often hides spicy geopolitical tensions that you can detect if you understand the context. AI reads the words but misses the subtext entirely.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#the-collaborative-model-you-provide-expertise-ai-provides-scale",
    "href": "foundations_intro.html#the-collaborative-model-you-provide-expertise-ai-provides-scale",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.6 The Collaborative Model: You Provide Expertise, AI Provides Scale",
    "text": "2.6 The Collaborative Model: You Provide Expertise, AI Provides Scale\nThe most effective approach treats AI as a collaborator rather than a replacement. Here’s how to think about the division of labor:\nYour Unique Value:\n\nDomain expertise and contextual understanding\nCritical analysis and theoretical frameworks\nEthical judgment and interpretation\nUnderstanding of implicit meanings and power dynamics\nAbility to validate and verify AI outputs\n\nAI’s Unique Value:\n\nProcessing large volumes of text quickly\nIdentifying patterns across many documents\nGenerating first drafts and creative alternatives\nHandling routine, time-consuming tasks\nProviding different perspectives to consider",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#triaging-tasks-along-the-frontier",
    "href": "foundations_intro.html#triaging-tasks-along-the-frontier",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.7 Triaging Tasks Along the Frontier",
    "text": "2.7 Triaging Tasks Along the Frontier\nUse the jagged frontier concept to categorize your research tasks:\n\n2.7.1 Human-Only Tasks\nTasks where AI is unreliable or where human judgment is essential:\n\nFinal interpretation of sensitive field data\nEthical analysis of research implications\nUnderstanding implicit cultural dynamics\nMaking final decisions about research direction\n\n\n\n2.7.2 Collaborative Tasks (Near the Frontier)\nTasks where AI can help but requires careful human oversight:\n\nLiterature reviews (AI helps find patterns, you verify and interpret)\nData analysis (AI helps with initial coding, you validate themes)\nCross-language work (AI provides translations, you check accuracy)\nGrant writing (AI creates drafts, you ensure accuracy and voice)\n\n\n\n2.7.3 AI-Assisted Tasks (Inside the Frontier)\nTasks you can safely delegate with light oversight:\n\nFirst-pass summarization of documents\nFormatting and citation cleanup\nTranslation of straightforward technical content\nCreating multiple versions of the same content for different audiences",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#finding-your-own-jagged-frontier",
    "href": "foundations_intro.html#finding-your-own-jagged-frontier",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.8 Finding Your Own Jagged Frontier",
    "text": "2.8 Finding Your Own Jagged Frontier\nThe jagged frontier varies between individuals, research domains, and even specific projects. You need to discover it yourself through experimentation. Here’s how:\nStart with your own work: Begin by testing AI on your own papers and research. You’ll quickly spot when it gets things wrong because you know the material intimately.\nBegin with low-stakes tasks: Try AI first on tasks where errors won’t matter much—reformatting text, creating bullet point summaries, or generating initial ideas.\nTest systematically: When you find a task AI handles well, try similar but slightly different tasks to map the boundaries of its capabilities.\nStay updated: The frontier is expanding rapidly but unevenly. AI that was terrible at math six months ago may now be excellent due to integrated calculation tools. Assume the AI you’re working with today is the worst AI you’ll ever use.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#key-principles-for-success",
    "href": "foundations_intro.html#key-principles-for-success",
    "title": "2  Understanding LLMs as Collaborative Research Assistants",
    "section": "2.9 Key Principles for Success",
    "text": "2.9 Key Principles for Success\n\nAlways verify: Never trust AI output without checking, especially for facts, citations, or quantitative claims.\nUse your expertise: Work with AI on topics where you have deep knowledge so you can catch errors and guide the process effectively.\nEmbrace iteration: AI works best through conversation and refinement, not one-shot requests.\nMaintain critical thinking: AI should amplify your analytical capabilities, not replace them.\nDocument your discoveries: Keep track of what works and what doesn’t for your specific research context.\n\nThe goal isn’t to become an AI expert—it’s to become more effective at research by understanding how to collaborate with these powerful but imperfect tools. In the next section, we’ll explore the practical considerations of choosing and using specific AI systems for academic work.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html",
    "href": "foundations_considerations.html",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "",
    "text": "3.1 Learning Objectives\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#learning-objectives",
    "href": "foundations_considerations.html#learning-objectives",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "",
    "text": "Distinguish between web interfaces and API approaches and understand when each is appropriate\nCompare open-source versus frontier model options and their trade-offs for academic research\nEvaluate the three major frontier model providers (OpenAI, Anthropic, Google) for your needs\nUnderstand key technical concepts like context windows and their practical implications\nMake informed decisions about tool selection based on your research requirements and technical comfort level",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#why-this-matters-for-your-research",
    "href": "foundations_considerations.html#why-this-matters-for-your-research",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.2 Why This Matters for Your Research",
    "text": "3.2 Why This Matters for Your Research\nBefore diving into specific tools, you need to understand the landscape of options available to you. Making the right choice about which tools to use can mean the difference between a frustrating experience that wastes your time and a transformative workflow that enhances your research capacity. This chapter will help you navigate the key decisions and understand why we’re focusing on Google Gemini for this workshop.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#two-ways-to-use-llms-web-interfaces-vs.-apis",
    "href": "foundations_considerations.html#two-ways-to-use-llms-web-interfaces-vs.-apis",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.3 Two Ways to Use LLMs: Web Interfaces vs. APIs",
    "text": "3.3 Two Ways to Use LLMs: Web Interfaces vs. APIs\nThe first major decision is how you want to interact with LLMs. There are two primary approaches:\n\n3.3.1 Web Interfaces (What We’ll Focus On)\nWhat it is: Using LLMs through a browser interface like ChatGPT, Claude, or Gemini. You type questions, upload documents, and get responses in real-time.\nBenefits:\n\nNo coding required\nImmediate access\nPerfect for exploratory research\nGood for one-off tasks\nBuilt-in features like document upload and citation\n\nLimitations:\n\nManual process for each query\nTime-consuming for repetitive tasks\nHarder to maintain consistency across large projects\nLimited ability to process hundreds of documents systematically\n\n\n\n3.3.2 APIs (Application Programming Interfaces)\nWhat it is: Using code to send requests to LLM services programmatically. Instead of typing in a web interface, you write scripts that automatically send queries and process responses.\nBenefits:\n\nCan process thousands of documents automatically\nConsistent methodology across large datasets\nReproducible workflows\nCost-effective for large-scale projects\nCan integrate with existing data analysis pipelines\n\nLimitations:\n\nRequires coding skills (Python, R, etc.)\nMore complex setup and debugging\nNeed to handle rate limits and error management\nSteeper learning curve\n\n\n\n3.3.3 Our Workshop Focus\nBecause this workshop assumes little previous LLM experience and no coding background, we’ll focus primarily on web interfaces—tools you can start using immediately. However, in our final section, we’ll discuss how we used APIs to classify 18,000 Chinese lending projects, showing you what becomes possible when you’re ready to scale up.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#open-source-vs.-frontier-models",
    "href": "foundations_considerations.html#open-source-vs.-frontier-models",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.4 Open-Source vs. Frontier Models",
    "text": "3.4 Open-Source vs. Frontier Models\n\n3.4.1 Open-Source Models\nWhat they are: AI models whose code and weights are publicly available. Examples include Meta’s Llama, Mistral, and various models from Hugging Face.\nBenefits:\n\nPrivacy: You can run them on your own servers\nReproducibility: Exact model versions remain available\nCost: Can be free if you have computing resources\nCustomization: Can fine-tune for specific tasks\n\nLimitations:\n\nCapability gap: Generally less capable than frontier models\nTechnical complexity: Require significant technical skills to deploy\nInfrastructure costs: Need expensive cloud computing for larger models\nInconsistent quality: Wide variation in performance\n\n\n\n\n\n\n\nOur Experience with Open-Source Models\n\n\n\nIn our Chinese lending classification project, we tested Meta’s Llama 3.3 alongside frontier models. It was really bad. While open-source models are improving rapidly, they’re not yet competitive with frontier models for complex research tasks.\n\n\n\n\n3.4.2 Frontier Models\nWhat they are: The most advanced models from major AI companies: OpenAI (ChatGPT), Anthropic (Claude), and Google (Gemini).\nBenefits:\n\nSuperior performance: Best available capabilities for most tasks\nEase of use: Polished interfaces and user experience\nRegular updates: Continuous improvements and new features\nReliability: More consistent and predictable outputs\n\nLimitations:\n\nCost: Subscription fees for full access\nPrivacy concerns: Your data goes to third-party companies\nLess control: Can’t customize or guarantee model availability\nBlack box: Don’t know exactly how they work\n\nFor most academic researchers starting with LLMs, frontier models are the better choice. They’re simply more capable and easier to use, allowing you to focus on your research rather than wrestling with technical infrastructure.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#the-three-frontier-model-providers",
    "href": "foundations_considerations.html#the-three-frontier-model-providers",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.5 The Three Frontier Model Providers",
    "text": "3.5 The Three Frontier Model Providers\nAll three major providers offer both free and paid tiers. I strongly recommend paying for at least one service—paid tiers provide better data privacy, higher usage limits, and faster access to new models.\n\n3.5.1 OpenAI (ChatGPT)\n\nStrengths: Deep Research tool, strong reasoning models (o3 Pro)\nBest for: Complex problem-solving, comprehensive research synthesis\n\n\n\n3.5.2 Anthropic (Claude)\n\nStrengths: Excellent for coding and writing tasks\nBest for: R/Python programming assistance, high-quality text generation\n\n\n\n3.5.3 Google (Gemini)\n\nStrengths: Largest context window, good citations, NotebookLM integration\nBest for: Working with large documents, academic research workflows",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#why-were-focusing-on-google-gemini",
    "href": "foundations_considerations.html#why-were-focusing-on-google-gemini",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.6 Why We’re Focusing on Google Gemini",
    "text": "3.6 Why We’re Focusing on Google Gemini\nWhile all three providers have their strengths, Google Gemini offers several advantages particularly relevant for academic research:\n\n3.6.1 1. Massive Context Window\n\n\n\n\n\n\nWhat is a Context Window?\n\n\n\nA context window is how much text an AI can “remember” and work with at one time. Think of it like the AI’s working memory. Current context windows:\n\nGemini 2.5 Pro: 1 million tokens (roughly 750,000 words)\nOpenAI GPT-4: ~200,000 tokens (roughly 150,000 words)\nAnthropic Claude: ~200,000 tokens (roughly 150,000 words)\n\nIn practical terms: Gemini can process about 10-15 typical academic papers simultaneously, while other models can handle 2-3 papers. This is transformative for literature reviews and cross-document analysis.\n\n\nThis enormous context window means you can:\n\nUpload multiple research papers simultaneously\nWork with entire book chapters or reports\nMaintain context across long conversations\nAnalyze patterns across large document collections\n\n\n\n3.6.2 2. Built-in Citation Features\nWhen you upload documents to Gemini, it automatically cites the specific portions where it finds information. This is invaluable for academic workflows where you need to trace claims back to source materials.\n\n\n3.6.3 3. NotebookLM Integration\nNotebookLM allows you to upload up to 300 documents and ask questions across the entire corpus. It provides exact text passages from your PDFs, making it excellent for exploratory analysis. In our ODI research, we used NotebookLM to analyze a decade of annual reports from Chinese policy banks—something that would have taken weeks manually.\n\n\n3.6.4 4. Strong Performance on Benchmarks\n\n\n\n\n\n\nUnderstanding LLM Benchmarks\n\n\n\nLLM benchmarks are standardized tests that measure model performance across different tasks. Popular benchmarks include:\n\nMMLU: Measures knowledge across academic subjects\nHumanEval: Tests coding capabilities\nHellaSwag: Evaluates common-sense reasoning\n\nYou can track current performance at Vellum’s LLM Leaderboard.\nImportant caveats:\n\nBenchmarks don’t always capture what’s useful for your specific research\nGoodhart’s Law applies: “When a measure becomes a target, it ceases to be a good measure.” Companies now optimize specifically for benchmarks, which may not reflect real-world performance.\n\n\n\nGemini 2.5 Pro performs competitively on major benchmarks, though remember that benchmark performance doesn’t always translate to usefulness for your specific research needs.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#the-reality-of-provider-competition",
    "href": "foundations_considerations.html#the-reality-of-provider-competition",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.7 The Reality of Provider Competition",
    "text": "3.7 The Reality of Provider Competition\nDespite our focus on Gemini for this workshop, I personally pay for premium access to all three major providers. Here’s why:\nModels update frequently: What’s best today may not be best next month. The competitive landscape changes rapidly.\nEach has unique strengths:\n\nI use Claude most often for coding (R and Python) and high-quality writing\nI use ChatGPT’s Deep Research for doing lengthy, high quality exploratory research\nI use Gemini for working with large document collections\n\nThis will all be outdated soon: The specific model capabilities I’m describing will likely be different by the time you read this. The field moves that fast.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#key-technical-concepts",
    "href": "foundations_considerations.html#key-technical-concepts",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.8 Key Technical Concepts",
    "text": "3.8 Key Technical Concepts\n\n3.8.1 Context Window (Revisited)\nThink of context window as the AI’s “working memory.” Larger windows allow for:\n\nMore complex conversations\nBetter understanding of document relationships\nAbility to maintain consistency across longer projects\n\n\n\n3.8.2 Tokens\nA rough conversion: 1 token ≈ 0.75 words in English. So 1 million tokens ≈ 750,000 words ≈ 1,500 pages of double-spaced text.\n\n\n3.8.3 Model Versions\nProviders regularly release new model versions. Pay attention to:\n\nPerformance improvements: Better accuracy, reasoning, or specialized capabilities\nCost changes: New models may be more or less expensive\nFeature additions: New capabilities like image analysis or coding tools",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#making-your-choice",
    "href": "foundations_considerations.html#making-your-choice",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.9 Making Your Choice",
    "text": "3.9 Making Your Choice\nFor this workshop, we’ll use Google Gemini because:\n\nIt’s excellent for document-heavy academic work\nThe citation features support good research practices\nThe large context window enables ambitious projects\nNotebookLM provides unique research capabilities\n\nHowever, I encourage you to experiment with all three providers. They each have strengths, and the best choice depends on your specific research needs, technical comfort level, and budget.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#cost-considerations",
    "href": "foundations_considerations.html#cost-considerations",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.10 Cost Considerations",
    "text": "3.10 Cost Considerations\n\n3.10.1 Free Tiers\nAll providers offer free access with limitations:\n\nUsage caps (messages per day/hour)\nAccess to older or less capable models\nFewer features\n\n\n\n3.10.2 Paid Tiers ($15-30/month typically)\n\nHigher usage limits\nAccess to latest models\nBetter data privacy protections\nPriority access during high-demand periods\n\n\n\n3.10.3 API Pricing\nFor programmatic use, you pay per token processed. Costs vary by model and provider, but typically range from $0.25-15 per million tokens.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "foundations_considerations.html#getting-started",
    "href": "foundations_considerations.html#getting-started",
    "title": "3  Key Considerations: Tools, Costs, and Contexts",
    "section": "3.11 Getting Started",
    "text": "3.11 Getting Started\nFor this workshop, you’ll need a free Google account and access to Gemini. We’ll walk through the setup process and begin exploring how these tools can enhance your research workflow.\nRemember: the goal isn’t to become an expert in any particular tool, but to understand how to evaluate and use these capabilities effectively for your research. The specific tools will continue evolving, but the principles we’re learning will remain relevant.\nIn our next section, we’ll move from theory to practice with hands-on prompt engineering—the skill that transforms mediocre AI outputs into genuinely useful research assistance.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Key Considerations: Tools, Costs, and Contexts</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html",
    "href": "apps_prompting.html",
    "title": "4  Prompt Engineering Basics",
    "section": "",
    "text": "4.0.1 Learning Objectives\nTentative time: 12 minutes",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#the-power-and-the-problem",
    "href": "apps_prompting.html#the-power-and-the-problem",
    "title": "4  Prompt Engineering Basics",
    "section": "4.1 The Power and the Problem",
    "text": "4.1 The Power and the Problem\nLarge Language Models are incredibly powerful tools, but they’re not clairvoyant. As Ethan Mollick observed in his work on “good enough prompting”:\n\n“LLMs (such as ChatGPT, Claude, or Bard) are powerful but not clairvoyant. They need sufficient information and clarity to produce useful responses.”\n\nThis insight captures a fundamental truth about working with AI: the quality of what you get out depends heavily on the quality of what you put in. But unlike Google searches where you can get away with a few keywords, LLMs work best when you treat them like a collaborative partner who needs context and clear direction.\nLet’s break down what this means practically:\n“Powerful” - LLMs can handle complex tasks that would take humans hours or days: summarizing dozens of papers, translating between languages, analyzing patterns in data, or drafting professional documents. They have access to vast knowledge and can process large amounts of text quickly.\n“But not clairvoyant” - They can’t read your mind or guess what you really need. They don’t know if you’re writing for undergraduates or policymakers, whether you need a formal or casual tone, or what specific angle matters most for your research.\n“Need sufficient information and clarity” - The more context and specific instructions you provide, the better the output. This is where prompt engineering comes in.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#from-our-mental-model-to-better-prompts",
    "href": "apps_prompting.html#from-our-mental-model-to-better-prompts",
    "title": "4  Prompt Engineering Basics",
    "section": "4.2 From Our Mental Model to Better Prompts",
    "text": "4.2 From Our Mental Model to Better Prompts\nRemember our “jagged frontier” mental model from Chapter 1? LLMs excel at some tasks (like summarizing text or finding patterns) but struggle with others (like providing current information or understanding subtle context). Good prompting helps you:\n\nNavigate the jagged frontier - Direct the AI toward tasks it handles well\nProvide human expertise - Give the AI the context and knowledge it lacks\nMaintain quality control - Structure requests so you can easily evaluate the output\n\nThink of it this way: you bring the expertise and judgment, the AI brings the scale and speed. But you need to communicate effectively to make this partnership work.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#the-power-of-chaining-prompts",
    "href": "apps_prompting.html#the-power-of-chaining-prompts",
    "title": "4  Prompt Engineering Basics",
    "section": "4.3 The Power of Chaining Prompts",
    "text": "4.3 The Power of Chaining Prompts\nOne advanced technique worth mentioning is prompt chaining - breaking complex tasks into sequential steps rather than asking for everything at once. This often produces better results because:\n\nEach step can be optimized for a specific task\nYou can review and refine the output before moving to the next step\nThe AI has clearer focus at each stage\nYou maintain better quality control throughout the process\n\nFor example, instead of asking “analyze this email thread and draft a response,” you might: 1. First, ask for analysis and clarification 2. Then, ask for a draft response based on that analysis\nThis approach is particularly valuable for complex or high-stakes communications where you want to ensure accuracy and appropriateness.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#two-powerful-prompt-enhancers",
    "href": "apps_prompting.html#two-powerful-prompt-enhancers",
    "title": "4  Prompt Engineering Basics",
    "section": "4.4 Two Powerful Prompt Enhancers",
    "text": "4.4 Two Powerful Prompt Enhancers\nBefore we move to the templates, here are two simple additions that can dramatically improve your prompts:\n“Please ask me clarifying questions” - This encourages the AI to seek additional information rather than making assumptions. It’s surprisingly effective at producing more tailored and useful outputs.\n“Tell me when you’re unsure about something” - This helps reduce hallucinations by encouraging the AI to admit uncertainty rather than fabricating plausible-sounding answers.\nThese simple additions can save you from misleading or inappropriate responses, especially when dealing with complex or sensitive topics.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#the-anatomy-of-an-effective-prompt",
    "href": "apps_prompting.html#the-anatomy-of-an-effective-prompt",
    "title": "4  Prompt Engineering Basics",
    "section": "4.5 The Anatomy of an Effective Prompt",
    "text": "4.5 The Anatomy of an Effective Prompt\nBased on research from Anthropic and other AI labs, effective prompts typically include:\n\n\n\n\n\n\nEssential Prompt Components\n\n\n\nContext - Who you are, what you’re working on, what the AI needs to know Task - What specifically you want the AI to do\nFormat - How you want the output structured Constraints - Any limitations, requirements, or things to avoid Examples - Sample inputs/outputs if helpful\n\n\nFor academic research, this might look like:\nContext: I'm a development researcher studying urban poverty in South Asia\nTask: Summarize the key findings from this paper about migration patterns\nFormat: 3-4 bullet points focusing on policy implications\nConstraints: Keep it under 200 words, use objective academic language\n[Then upload or paste the paper or abstract]",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#hands-on-activity-building-your-research-context",
    "href": "apps_prompting.html#hands-on-activity-building-your-research-context",
    "title": "4  Prompt Engineering Basics",
    "section": "4.6 Hands-On Activity: Building Your Research Context",
    "text": "4.6 Hands-On Activity: Building Your Research Context\nLet’s practice with something directly useful for your research. We’ll create a professional context that you can reuse across different AI conversations.\n\n4.6.1 Step 1: Create Your Professional Context\nCopy and modify this template with your own information:\n# [Your Name] - Professional Context\n\n## Domain Expertise & Background\n[Describe your main research areas, methodology preferences, and key expertise. Include your educational background and any relevant professional experience.]\n\n## Current Roles & Affiliations\n[List your current positions, institutional affiliations, and key responsibilities]\n\n## Research Focus Areas\n[Outline your main research interests and current projects]\n\n## Communication Style & Audience\n[Describe who you typically write for and how you prefer to communicate research findings]\n\n## Technical Approach\n[Mention any specific tools, methods, or analytical approaches you use]\n\n\n\n\n\n\nExample Professional Context\n\n\n\nHere’s how this might look for a researcher:\n# Teal Emery - Professional Context\n\n## Domain Expertise & Background\nI'm a research consultant specializing in sovereign debt, emerging markets, and Chinese lending to developing countries. I combine domain expertise with data science tools to turn complex information into actionable insights. I have 10+ years of experience as an emerging markets investor and analyst, including 7 years at Morgan Stanley as a sovereign research analyst covering China, Africa, the Middle East, and other emerging markets.\n\n## Current Roles & Affiliations\n- Founder & Lead Researcher at Teal Insights\n- Research Consultant at AidData\n- Fellow at Energy for Growth Hub\n- Adjunct Lecturer at Johns Hopkins SAIS\n\n## Research Focus Areas\n- Sovereign debt sustainability and restructuring\n- Chinese lending and development finance\n- Renewable energy financing in low-income countries\n- Building transparent, reproducible research tools\n\n## Communication Style & Audience\nI write for policymakers, economists, and graduate students who are intelligent but may not share my specific domain expertise. I value clarity over complexity and aim to make technical concepts accessible without oversimplification.\n\n\n\n\n4.6.2 Step 2: Test the Difference\nNow let’s see how context changes AI responses. Try these two prompts with your chosen AI tool:\nPrompt A (Without Context):\nWhat are some important research questions about social protection in developing countries?\nPrompt B (With Context):\n[Paste your professional context here]\n\nGiven my research background and expertise, what are 5 specific research questions about social protection in developing countries that would be valuable and feasible for my work? Focus on areas where my mixed-methods approach and regional expertise would be particularly valuable.\n\n\n4.6.3 Step 3: Observe and Refine\nCompare the two outputs: - Which response is more specific and useful? - Which better reflects your actual research interests? - How might you refine your context or prompt for even better results?",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#common-mistakes-and-how-to-fix-them",
    "href": "apps_prompting.html#common-mistakes-and-how-to-fix-them",
    "title": "4  Prompt Engineering Basics",
    "section": "4.7 Common Mistakes and How to Fix Them",
    "text": "4.7 Common Mistakes and How to Fix Them\n\n4.7.1 Mistake 1: Treating AI Like Google\nProblem: Asking factual questions without context Instead: Provide documents and ask for analysis\n❌ “What’s the poverty rate in Nigeria?” ✅ “Based on the survey data I’m sharing below, what are the key trends in poverty rates across different regions of Nigeria?”\n\n\n4.7.2 Mistake 2: Vague Requests\nProblem: “Tell me about X” or “Help me with Y” Instead: Be specific about the task and output format\n❌ “Help me with my literature review” ✅ “Summarize the main arguments from these 5 papers about microfinance, focusing on conflicting findings about impact on women’s empowerment. Format as a comparison table.”\n\n\n4.7.3 Mistake 3: No Quality Control\nProblem: Accepting AI output without verification Instead: Ask for sources, evidence, or reasoning\n❌ Just using whatever the AI produces ✅ “Show me the specific quotes from the papers that support each of these conclusions”\n\n\n4.7.4 Mistake 4: Overwhelming the AI\nProblem: Asking for too much at once Instead: Break complex tasks into steps\n❌ “Analyze this dataset, create visualizations, write a report, and suggest policy recommendations” ✅ “First, help me identify the key patterns in this dataset. Then we’ll work on visualizations.”",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#templates-for-common-research-tasks",
    "href": "apps_prompting.html#templates-for-common-research-tasks",
    "title": "4  Prompt Engineering Basics",
    "section": "4.8 Templates for Common Research Tasks",
    "text": "4.8 Templates for Common Research Tasks\nHere are some proven prompt templates you can adapt:\n\n4.8.1 Complex Email Thread Analysis\n[Your professional context]\n\nI need to respond to this complex email thread. Please help me by:\n1. Summarizing the key issues being discussed\n2. Identifying what questions or decisions need my input\n3. Noting any deadlines or urgent items\n4. Flagging any potential conflicts or sensitive topics\n5. Suggesting 2-3 key points for my response\n\nUpload the entire email thread below. Include any relevant background context about the project, relationships, or institutional dynamics that might help me craft an appropriate response.\n\nPlease ask me clarifying questions if anything is unclear, and tell me when you're unsure about something rather than guessing.\n\nEmail thread: [upload the full thread]\nAdditional context: [describe the project, your role, any politics or sensitivities]\nFollow-up prompt for drafting:\nBased on your analysis above, please draft a professional response email that:\n- Addresses the key points requiring my input\n- Maintains an appropriate tone for the relationships involved\n- Includes any necessary next steps or commitments\n- Is structured for busy people to read and respond to quickly (clear subject line, key points upfront, specific asks)\n- Keeps the response concise but comprehensive\n\nI'll review and edit this draft carefully before sending.\n\n\n4.8.2 Research Question Brainstorming\n[Your professional context]\n\nI want to brainstorm new research directions building on my existing work. Please upload 2-3 of my recent papers or abstracts that represent my current research focus.\n\nBased on my previous work and the additional context below, generate 6 research questions that would be:\n- Natural extensions or new directions from my existing research\n- Feasible given my established methodological expertise\n- Policy-relevant for [specific context/region where you work]\n- Novel enough to contribute meaningfully to the literature\n\nAdditional context about my interests for new research:\n- [Describe any new areas you're curious about]\n- [Mention any gaps you've noticed in your field]\n- [Note any new data sources or methods you'd like to explore]\n- [Describe any policy questions that keep coming up in your work]\n\nPlease ask me clarifying questions if you need more information about my specific interests or constraints, and tell me when you're unsure about something.\n\nFormat as a numbered list with brief explanation for each, including how it builds on my existing work.\n\n\n4.8.3 Writing Enhancement\n[Your professional context]\n\nPlease review this draft paragraph from my paper and suggest improvements for:\n- Clarity and flow\n- Academic tone appropriate for [specific journal/audience]\n- Strength of argument\n- Any unclear or weak statements\n\nTo help you provide better feedback, please upload:\n- A sample article previously published in this outlet (so you understand the style)\n- Any submission guidelines or style guidelines I should follow\n- The draft text I want you to review\n\nDraft: [paste or upload your text]",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#building-your-prompt-library",
    "href": "apps_prompting.html#building-your-prompt-library",
    "title": "4  Prompt Engineering Basics",
    "section": "4.9 Building Your Prompt Library",
    "text": "4.9 Building Your Prompt Library\nAs you use AI tools more, you’ll develop a personal collection of effective prompts. Consider:\n\nSaving successful prompts - Keep a document with templates that work well\nIterating and improving - Note what works and what doesn’t\nSharing with colleagues - Good prompts are valuable resources to share\nStaying organized - Group prompts by task type (analysis, writing, brainstorming)",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#what-you-can-do-now",
    "href": "apps_prompting.html#what-you-can-do-now",
    "title": "4  Prompt Engineering Basics",
    "section": "4.10 What You Can Do Now",
    "text": "4.10 What You Can Do Now\n\nCreate your professional context using the template above\nTest the difference context makes with a real research question\nTry one literature review prompt with a paper you’re currently reading\nSave your best prompts for future use",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_prompting.html#going-deeper",
    "href": "apps_prompting.html#going-deeper",
    "title": "4  Prompt Engineering Basics",
    "section": "4.11 Going Deeper",
    "text": "4.11 Going Deeper\nFor more advanced prompt engineering techniques, see:\n\nAnthropic’s Prompt Engineering Guide\nChapter 2.2 on creating reusable “Gems” for repeated tasks\n\nRemember: Good prompting is a skill that improves with practice. Start with these basics, then gradually experiment with more sophisticated techniques as you become comfortable with the fundamentals.\n\nUp next: Chapter 2.2 - Building Research Projects and Creating Your First Gem",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prompt Engineering Basics</span>"
    ]
  },
  {
    "objectID": "apps_gems.html",
    "href": "apps_gems.html",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "",
    "text": "5.1 Learning Objectives\nTentative time: 12 minutes\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#learning-objectives",
    "href": "apps_gems.html#learning-objectives",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "",
    "text": "Understand Gems as saved research assistants and how they differ from regular prompts\nCreate a reusable Gem that incorporates your professional context for better AI interactions\nDesign Gems for common research tasks like literature reviews, grant writing, and data analysis\nApply the same concepts to Claude Projects and ChatGPT Custom GPTs\nBuild a personal library of research tools that improve over time",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#what-are-gems-and-why-they-matter",
    "href": "apps_gems.html#what-are-gems-and-why-they-matter",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.2 What Are Gems and Why They Matter",
    "text": "5.2 What Are Gems and Why They Matter\nThink of a Gem as a specialized research assistant that you’ve trained for specific tasks. Instead of starting from scratch each time you need help with literature reviews or grant applications, you can create a Gem that already knows your research context, preferred style, and common requirements.\n\n\n\n\n\n\nGems Across Platforms\n\n\n\nGoogle calls them “Gems,” but the concept exists across all major AI platforms:\n\nGoogle Gemini: Gems\nClaude: Projects\n\nChatGPT: Custom GPTs\n\nThe functionality is essentially the same—you’re creating a specialized version of the AI with specific instructions and context.\n\n\nWhy Gems are valuable:\n\nConsistency: Your Gem applies the same high-quality instructions every time\nEfficiency: No need to re-enter your professional context or detailed instructions\nSpecialization: Each Gem can be optimized for specific research tasks\nSharing: You can share useful Gems with colleagues (though be mindful of any sensitive context)",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#the-power-of-context-your-professional-gem",
    "href": "apps_gems.html#the-power-of-context-your-professional-gem",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.3 The Power of Context: Your Professional Gem",
    "text": "5.3 The Power of Context: Your Professional Gem\nRemember the professional context template from our prompting chapter? This is perfect for your first Gem. When you embed your research background, expertise, and communication style into a Gem, every interaction becomes more targeted and useful.\n\n5.3.1 Creating Your Professional Context Gem\nLet’s walk through creating a Gem that incorporates your professional context:\nStep 1: Access Gem Creation\n\nGo to gemini.google.com\nOn the left sidebar, click “Explore Gems”\nClick “New Gem”\n\nStep 2: Name Your Gem Give it a clear, descriptive name like “Research Assistant - [Your Name]” or “My Academic Context”\nStep 3: Write Your Instructions Use this template, filling in your specific details:\n# Professional Research Assistant Instructions\n\n## About the Researcher\n[Your name] is a researcher specializing in [your main research areas]. [Brief background including education, current position, and key expertise areas].\n\n## Current Roles & Affiliations\n- [List your current positions and institutional affiliations]\n- [Any relevant professional experiences]\n\n## Research Focus Areas\n- [Your main research interests]\n- [Current projects or areas of investigation]\n- [Methodological approaches you prefer]\n\n## Communication Style & Audience\nI typically write for [describe your audience - policymakers, academics, graduate students, etc.]. I value [your communication preferences - clarity over complexity, accessible language, etc.].\n\n## Technical Approach\n[Mention any specific tools, software, or analytical methods you use regularly]\n\n## How to Assist Me\nWhen I ask for help:\n1. **Draw on my expertise**: Remember that I have deep knowledge in my field, so you can use more sophisticated concepts and terminology where appropriate\n2. **Match my communication style**: Write in a way that fits how I typically communicate with my audience\n3. **Ask clarifying questions**: If you need more context about my specific needs or constraints, please ask\n4. **Provide sources when possible**: I value being able to trace information back to original sources\n5. **Be honest about limitations**: Tell me when you're uncertain about something rather than guessing\n\n## Areas Where I Most Need Help\n- [List 2-3 specific areas where AI assistance would be most valuable to your work]\n- [Examples: literature synthesis, initial data analysis, grant writing, translation, etc.]\n\nAlways remember: You're here to amplify my expertise, not replace it. Help me do more ambitious research by handling routine tasks while I focus on analysis, interpretation, and critical thinking.\nStep 4: Test Your Gem Use the preview panel to test your Gem with a question like: “What are some promising research directions building on my current work?”\nStep 5: Save and Refine Click “Save” and then continue using your Gem for various research tasks. You can always edit the instructions to improve them based on what you learn.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#essential-gems-for-research-workflows",
    "href": "apps_gems.html#essential-gems-for-research-workflows",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.4 Essential Gems for Research Workflows",
    "text": "5.4 Essential Gems for Research Workflows\nOnce you have your professional context Gem, consider creating specialized Gems for common research tasks:\n\n5.4.1 Literature Review Gem\nPerfect for analyzing papers, finding patterns, and identifying gaps:\n# Literature Review Specialist\n\nYou are an expert research assistant specializing in literature reviews and academic analysis.\n\n## Your Role\nHelp me efficiently analyze academic papers, identify key themes, find research gaps, and synthesize findings across multiple sources.\n\n## Key Capabilities\n- Summarize papers focusing on methodology, findings, and implications\n- Identify patterns and contradictions across multiple studies\n- Suggest research gaps and future directions\n- Help with citation analysis and reference management\n- Compare and contrast different theoretical approaches\n\n## Output Format\n- Use clear section headers\n- Provide specific page numbers or quotes when analyzing uploaded papers\n- Include methodological details when relevant\n- Highlight conflicting findings or debates in the literature\n- Always ask for clarification if the research question or focus is unclear\n\n## Quality Standards\n- Maintain academic rigor in analysis\n- Distinguish between authors' claims and empirical findings\n- Note limitations and methodological concerns\n- Provide balanced assessment of different perspectives\n\n\n5.4.2 Grant Writing Gem\nSpecialized for funding applications and project proposals:\n# Grant Writing Assistant\n\nYou are an expert in academic grant writing and research proposal development.\n\n## Your Role\nHelp me develop compelling, well-structured grant proposals that clearly communicate research value and feasibility.\n\n## Key Capabilities\n- Develop clear problem statements and research questions\n- Structure proposals with logical flow and compelling narrative\n- Identify potential funding sources and tailor applications accordingly\n- Strengthen methodology sections with appropriate detail\n- Create realistic timelines and budget justifications\n- Ensure compliance with funder requirements\n\n## Output Format\n- Use active voice and clear, accessible language\n- Include specific sections as requested (abstract, aims, methodology, etc.)\n- Provide alternative phrasings for key concepts\n- Suggest evidence to support claims\n- Flag areas needing additional development\n\n## Quality Standards\n- Balance ambition with feasibility\n- Ensure methodology matches research questions\n- Provide clear value proposition for funders\n- Include realistic assessment of challenges and mitigation strategies\n\n\n5.4.3 Data Analysis Gem\nFor help with statistical analysis and interpretation:\n# Data Analysis Assistant\n\nYou are an expert in research methodology and statistical analysis.\n\n## Your Role\nHelp me design analysis strategies, interpret results, and troubleshoot analytical problems.\n\n## Key Capabilities\n- Suggest appropriate statistical methods for research questions\n- Help interpret statistical outputs and findings\n- Identify potential confounding variables or methodological concerns\n- Assist with data visualization strategies\n- Provide guidance on sample size and power analysis\n- Help with coding and data management tasks\n\n## Output Format\n- Explain statistical concepts in accessible language\n- Provide step-by-step analysis guidance\n- Include assumptions and limitations of suggested methods\n- Offer multiple approaches when appropriate\n- Link methodology to research questions\n\n## Quality Standards\n- Ensure statistical approaches match data type and research design\n- Emphasize importance of checking assumptions\n- Encourage transparency in reporting methods and limitations\n- Promote reproducible research practices",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#advanced-gem-strategies",
    "href": "apps_gems.html#advanced-gem-strategies",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.5 Advanced Gem Strategies",
    "text": "5.5 Advanced Gem Strategies\n\n5.5.1 Uploading Reference Materials\nYou can upload files to your Gems to provide additional context:\n\nStyle guides from your target journals or publishers\nSample papers that represent the quality and style you’re aiming for\nInstitutional guidelines for grants or reports\nData dictionaries or codebooks for your projects\n\n\n\n5.5.2 Iterative Improvement\nYour Gems should evolve with your research:\n\nTrack what works: Note when a Gem produces particularly helpful outputs\nRefine instructions: Update your Gems based on what you learn about effective prompting\nAdd new capabilities: Expand your Gems’ roles as you discover new use cases\nCreate specialized versions: Develop task-specific variations of your main Gems\n\n\n\n5.5.3 Sharing and Collaboration\n\n\n\n\n\n\nBeyond AI: Templates for Human Research Assistants\n\n\n\nThese same detailed instruction templates work brilliantly for human research assistants too. At Teal Insights, we use similar structured briefs when working with our research team across Nigeria, Kenya, and the US.\nCreating clear, detailed instructions helps ensure:\n\nConsistent quality across different team members\nEfficient onboarding for new researchers\nStandardized approaches to literature reviews and analysis\nClear expectations for deliverables and format\n\nWhether you’re working with AI or human assistants, taking time to articulate your requirements clearly pays dividends in output quality.\n\n\n\n\n\n\n\n\nPrivacy Considerations\n\n\n\nBe cautious about sharing Gems that contain sensitive information about your research, personal details, or institutional affiliations. Consider creating “public” versions of your Gems with generic instructions for sharing with colleagues.\n\n\nYou can share Gems with research collaborators to ensure consistent AI assistance across your team. This is particularly valuable for:\n\nMulti-author projects: Ensuring consistent style and approach\nResearch groups: Sharing effective prompting strategies\nInstitutional best practices: Developing standard AI tools for your department",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#building-your-gem-library",
    "href": "apps_gems.html#building-your-gem-library",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.6 Building Your Gem Library",
    "text": "5.6 Building Your Gem Library\nAs you become more comfortable with Gems, consider developing a comprehensive library:\nCore Research Gems:\n\nProfessional context (your main research assistant)\nLiterature review specialist\nGrant writing assistant\nData analysis helper\n\nSpecialized Gems:\n\nConference presentation creator\nPolicy brief writer\nTeaching material developer\nCross-disciplinary translator\n\nWorkflow Gems:\n\nEmail drafting assistant\nMeeting note analyzer\nProject timeline creator\nBibliography manager",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#hands-on-activity-create-your-first-gem",
    "href": "apps_gems.html#hands-on-activity-create-your-first-gem",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.7 Hands-On Activity: Create Your First Gem",
    "text": "5.7 Hands-On Activity: Create Your First Gem\nLet’s practice by creating your professional context Gem:\n\nOpen Gemini and navigate to Gems\nCreate a new Gem using the template above\nFill in your specific details (research areas, expertise, communication style)\nTest your Gem with a research question you’re currently working on\nRefine the instructions based on the quality of the response\n\nThen, if time permits, create a second Gem for a specific research task you do regularly.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#what-can-go-wrong-and-how-to-fix-it",
    "href": "apps_gems.html#what-can-go-wrong-and-how-to-fix-it",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.8 What Can Go Wrong (and How to Fix It)",
    "text": "5.8 What Can Go Wrong (and How to Fix It)\n\n5.8.1 Common Issues:\nToo generic: Gem instructions that are too broad produce mediocre results → Solution: Be specific about your research context and preferred outputs\nToo rigid: Overly detailed instructions that don’t allow for flexibility → Solution: Provide clear guidance while leaving room for the AI to adapt to different queries\nOutdated context: Gems that don’t reflect your current research focus → Solution: Regularly review and update your Gems as your research evolves\nForgetting to save: Working with a Gem in preview mode without saving → Solution: Always click “Save” after creating or editing a Gem",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#integration-with-your-research-workflow",
    "href": "apps_gems.html#integration-with-your-research-workflow",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.9 Integration with Your Research Workflow",
    "text": "5.9 Integration with Your Research Workflow\nGems work best when they become part of your regular research routine:\n\nDaily literature review: Use your Literature Review Gem for new papers\nWeekly planning: Use your Professional Context Gem for project prioritization\nGrant deadlines: Use your Grant Writing Gem for proposal development\nData analysis sessions: Use your Data Analysis Gem for statistical guidance",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#what-you-can-do-now",
    "href": "apps_gems.html#what-you-can-do-now",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.10 What You Can Do Now",
    "text": "5.10 What You Can Do Now\n\nCreate your Professional Context Gem using the template provided\nTest it with a current research question to see how context improves responses\nIdentify 2-3 routine research tasks that would benefit from specialized Gems\nCreate one task-specific Gem for your most common research need\nShare your best Gems with colleagues (being mindful of privacy)",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_gems.html#going-deeper",
    "href": "apps_gems.html#going-deeper",
    "title": "5  Creating Custom Research Assistants: Your First Gem",
    "section": "5.11 Going Deeper",
    "text": "5.11 Going Deeper\nThe same principles apply to Claude Projects and ChatGPT Custom GPTs. Once you master Gems, you can create similar specialized assistants across all major AI platforms, giving you flexible options for different research needs.\nRemember: the goal isn’t to create perfect Gems immediately, but to build a library of increasingly useful research tools that evolve with your work. Start simple, iterate based on what you learn, and gradually develop more sophisticated specialized assistants.\n\nUp next Literature Review Enhancement Techniques",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Creating Custom Research Assistants: Your First Gem</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html",
    "href": "apps_lit_review.html",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "",
    "text": "6.1 Learning Objectives\nTentative time: 15 minutes\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#learning-objectives",
    "href": "apps_lit_review.html#learning-objectives",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "",
    "text": "Apply the jagged frontier concept to understand where LLMs excel in literature processing\nUse LLMs as an efficient funnel to identify papers worth reading in detail\nCreate structured summaries that capture the information you need from academic papers\nTranslate content between languages to include more diverse sources in your research\nBridge disciplinary boundaries by translating between different academic jargons\nCustomize your approach for your specific research domain and needs",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#why-this-matters-the-information-deluge-problem",
    "href": "apps_lit_review.html#why-this-matters-the-information-deluge-problem",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.2 Why This Matters: The Information Deluge Problem",
    "text": "6.2 Why This Matters: The Information Deluge Problem\nThere’s an explosion of research being published. Even within narrow subfields, keeping up with the literature is becoming impossible. The volume of academic publishing has grown dramatically in recent decades, with researchers facing an ever-expanding universe of potentially relevant papers.\nYou have a job, a family, and a life outside of research. You can’t read everything that looks interesting. But you also can’t afford to miss important developments in your field or related areas that might inform your work.\nThis is where LLMs can be transformative—not by replacing careful reading and analysis, but by serving as an intelligent filter that helps you identify what deserves your limited time and attention.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#the-jagged-frontier-where-llms-excel-at-literature-processing",
    "href": "apps_lit_review.html#the-jagged-frontier-where-llms-excel-at-literature-processing",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.3 The Jagged Frontier: Where LLMs Excel at Literature Processing",
    "text": "6.3 The Jagged Frontier: Where LLMs Excel at Literature Processing\nLet’s apply our jagged frontier concept to literature review tasks:\nInside the Frontier (LLMs excel): - Creating structured summaries of complex texts - Identifying key arguments and findings - Extracting specific information (methodology, data sources, conclusions) - Translating between languages for initial understanding - Bridging disciplinary jargon differences - Finding patterns across multiple documents\nOutside the Frontier (LLMs struggle): - Understanding implicit context and unwritten assumptions - Grasping subtle theoretical nuances - Recognizing what’s missing or what contradicts domain knowledge - Making critical judgments about research quality - Understanding the political or social subtext of academic work",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#the-scale-advantage-time-mathematics",
    "href": "apps_lit_review.html#the-scale-advantage-time-mathematics",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.4 The Scale Advantage: Time Mathematics",
    "text": "6.4 The Scale Advantage: Time Mathematics\nLet’s do some back-of-the-envelope math to understand the scale advantage:\n\n\n\n\n\n\nReading Time Reality Check\n\n\n\nTypical reading speeds for complex academic text:\n\nAverage reading speed: 200-250 words per minute\nAcademic paper reading (with comprehension): 100-150 words per minute\nTypical academic paper: 6,000-8,000 words\n100-page report: ~25,000-30,000 words\n\nTime calculations:\n\nSingle academic paper: 40-80 minutes to read thoroughly\n100-page report: 3-5 hours of focused reading\nWeekly literature review (10 papers): 7-13 hours\n\nLLM processing:\n\nStructured summary of any paper: 30-60 seconds\nAnalysis of 100-page report: 2-3 minutes\nPattern analysis across 10 papers: 5-10 minutes\n\n\n\nThis isn’t about replacing careful reading—it’s about helping you decide what merits that careful reading. LLMs can process the volume while you focus your expertise on the papers that matter most.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#my-personal-literature-workflow",
    "href": "apps_lit_review.html#my-personal-literature-workflow",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.5 My Personal Literature Workflow",
    "text": "6.5 My Personal Literature Workflow\nHere’s the strategy I’ve developed and refined over the past year:\nAs a practitioner rather than an academic, I read a very broad array of materials: academic papers, IMF country reports, legislation, think tank papers, national policy documents, and more. Since these documents don’t all have “methodologies” or “research questions,” I keep my prompts broadly applicable and don’t want to switch between document types for first-order filtering.\nStep 1: Initial Filtering When I encounter potentially relevant documents, I use this prompt:\n[Consider adding your personal context prompt here for better results]\n\nPlease provide the full citation information for this document at the top, then create a detailed structured summary of this entire document, including any appendices. \n\nI need to understand:\n- The main argument or purpose\n- Key findings or conclusions\n- Important data, evidence, or examples\n- Any policy implications or practical applications\n- Who the intended audience appears to be\n\nFormat this as a structured summary with clear headings.\nStep 2: Section-by-Section Analysis For documents that pass the initial filter, I use:\nPlease create a detailed structured summary of each section of this document, including any appendices. For each section, tell me:\n- What the section covers\n- Key points or findings\n- Any specific data, evidence, or examples mentioned\n- How it relates to the overall argument\n\nFormat this as a structured summary with clear headings.\nThis helps me understand exactly where to find specific information I need.\nResults:\n\n95% of documents: The summary gives me what I need for peripheral understanding\n5% of documents: Worth reading in detail, and I know exactly which sections to focus on\nMy research assistants create these summaries and add them to our shared database",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#customizing-for-your-research-domain",
    "href": "apps_lit_review.html#customizing-for-your-research-domain",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.6 Customizing for Your Research Domain",
    "text": "6.6 Customizing for Your Research Domain\nThe generic prompts above work well, but you can customize them for your specific field and needs:\n\n6.6.1 For Social Science Research\n[Add your personal context prompt here if working individually, or brief context if sharing with others]\n\nYou are analyzing a social science paper. Please create a structured summary that includes:\n\n**Citation Information:**\n- Full citation in [your preferred format]\n- DOI or other permanent identifier\n- Publication venue and impact factor if available\n\n**Research Context:**\n- Geographic and temporal scope\n- Research domain (economics, sociology, political science, etc.)\n- Target population or units of analysis\n- Theoretical framework employed\n\n**Methodology:**\n- Research design (experimental, observational, qualitative, mixed methods)\n- Data collection methods and sources\n- Sample size and selection criteria\n- Analytical approach and tools used\n\n**Key Findings:**\n- Main empirical results\n- Statistical significance and effect sizes where relevant\n- Unexpected or counterintuitive findings\n- Robustness checks or sensitivity analyses\n\n**Broader Implications:**\n- Theoretical contributions\n- Policy recommendations\n- Practical applications\n- Limitations acknowledged by authors\n\n**Critical Assessment:**\n- Methodological strengths and weaknesses\n- Potential biases in approach\n- Generalizability concerns\n- Areas for future research\n\nInclude specific page numbers for key findings so I can locate them quickly.\n\n\n6.6.2 For Policy Research\n[Add your personal context prompt here if working individually, or brief context if sharing with others]\n\nAnalyze this policy paper with focus on:\n\n**Citation Information:**\n- Full citation in [your preferred format]\n- Publication type (working paper, policy brief, journal article, etc.)\n- Institutional affiliation of authors\n\n**Policy Problem:**\n- Issue definition and scope\n- Stakeholders affected\n- Current policy landscape\n\n**Evidence Base:**\n- What research/data informs the analysis\n- Quality and recency of evidence\n- Any evidence gaps acknowledged\n\n**Recommendations:**\n- Specific policy proposals\n- Implementation mechanisms\n- Resource requirements\n- Timeline considerations\n\n**Political Economy:**\n- Potential supporters and opponents\n- Implementation challenges\n- Unintended consequences discussed\n\nHighlight any quantitative estimates (costs, benefits, impacts) with page numbers.\n\n\n6.6.3 Creating Your Custom Gem\nOnce you’ve refined prompts that work well for your field, create a Gem (or Claude Project) to standardize this process:\n\nName it clearly: “Literature Review Assistant - [Your Field]”\nInclude your research context (your expertise, current projects, typical paper types)\nEmbed your refined prompts as the default approach\nAdd specific formatting preferences (citation style, section headings, etc.)",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#translation-two-types-of-bridge-building",
    "href": "apps_lit_review.html#translation-two-types-of-bridge-building",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.7 Translation: Two Types of Bridge-Building",
    "text": "6.7 Translation: Two Types of Bridge-Building\nLLMs excel at two types of translation that can dramatically expand your research scope:\n\n6.7.1 1. Language Translation\nThe Opportunity: Much important research is published in languages other than English. LLMs can provide initial translations that help you identify which papers merit professional translation.\nThe Reality Check: LLM translation quality reflects training data availability. For major languages (Spanish, French, German, Chinese, Arabic), quality is generally good. For less common languages, quality varies significantly.\nPractical Prompt:\nPlease translate this [source language] paper into English, then provide:\n\n1. A 3-sentence summary of the main argument\n2. The key empirical findings\n3. Any methodology that seems novel or interesting\n4. Whether this appears relevant to [your research area]\n\nYou can work with either the full paper or just the abstract - both options work well with current LLMs.\n\n[Upload paper or paste abstract]\n\nIf you're uncertain about any translation, please flag those sections.\nBest Practices:\n\nUpload full papers when possible - LLMs can handle them easily\nStart with abstracts for quick relevance assessment if you have many papers\nFor core sources, get professional translation\nBe aware of cultural context that might be lost in translation\nCheck technical terms against discipline-specific glossaries\n\n\n\n6.7.2 2. Cross-Disciplinary Translation\nThe Challenge: Academic jargon is efficient within disciplines but creates barriers between them. Important insights often remain trapped within narrow subdisciplines.\nThe Solution: LLMs can translate between academic jargons, helping you access insights from related fields.\nExample Prompt:\n[Consider adding your personal context prompt here for better results]\n\nThis paper is written for [source discipline] scholars using technical terminology that may not be familiar to [target discipline] researchers. \n\nPlease:\n1. Identify the key concepts and findings\n2. Explain them in plain language\n3. Suggest how these insights might apply to [target discipline]\n4. Highlight any methodological approaches that could be adapted\n\nFocus on practical applications and avoid oversimplification of complex ideas.\nReal-World Application: As a practitioner rather than an academic, I regularly need to understand and communicate across disciplines. I’m not a software engineer, but I need to speak intelligibly to software engineers to build open-source tools. I’m not a PhD economist, but I need to understand and evaluate complex economic models. I’m not a climate scientist, but I need to understand their findings to assess practical implications for the countries I advise.\nLLMs help me bridge these gaps by translating complex concepts into language I can understand, while preserving the essential insights. This enables me to: - Understand the intuitions from different fields - Identify relevant methodologies from other disciplines - Communicate effectively with diverse expert communities - Build interdisciplinary solutions to complex problems",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#hands-on-activity-your-literature-funnel",
    "href": "apps_lit_review.html#hands-on-activity-your-literature-funnel",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.8 Hands-On Activity: Your Literature Funnel",
    "text": "6.8 Hands-On Activity: Your Literature Funnel\nLet’s practice building your personal literature workflow:\nStep 1: Choose Your Papers Select 3 papers: one you know well, one you’re curious about, and one from a related but different field.\nStep 2: Apply the Funnel Use the basic structured summary prompt on all three papers.\nStep 3: Customize Based on the results, refine your prompt to better capture what you need for your research.\nStep 4: Test Translation If you have access to papers in other languages or from other disciplines, try the translation approaches.\nStep 5: Create Your Gem Build a reusable prompt that incorporates your refinements.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#common-pitfalls-and-how-to-avoid-them",
    "href": "apps_lit_review.html#common-pitfalls-and-how-to-avoid-them",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.9 Common Pitfalls and How to Avoid Them",
    "text": "6.9 Common Pitfalls and How to Avoid Them\n\n6.9.1 Pitfall 1: Trusting Without Verification\n\nProblem: Accepting LLM summaries without checking against the original\nSolution: Always verify key claims, especially quantitative findings\n\n\n\n6.9.2 Pitfall 2: Missing Subtle Arguments\n\nProblem: LLMs can miss theoretical nuances or implicit arguments\nSolution: Use summaries to identify promising papers, then read the key sections yourself\n\n\n\n6.9.3 Pitfall 3: Translation Overconfidence\n\nProblem: Assuming translations capture all important meaning\nSolution: Get professional translation for sources central to your argument\n\n\n\n6.9.4 Pitfall 4: Generic Prompts\n\nProblem: Using one-size-fits-all prompts that miss field-specific insights\nSolution: Customize prompts for your discipline and research questions",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#what-you-can-do-now",
    "href": "apps_lit_review.html#what-you-can-do-now",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.10 What You Can Do Now",
    "text": "6.10 What You Can Do Now\n\nTest the basic workflow with 3 papers of different types\nCreate your customized prompt based on your field’s specific needs\nBuild your Literature Review Gem with your refined approach\nTry cross-disciplinary translation on a paper from a related field\nStart your literature database with structured summaries",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_lit_review.html#the-bigger-picture",
    "href": "apps_lit_review.html#the-bigger-picture",
    "title": "6  Literature Review Enhancement: Widening Your Net",
    "section": "6.11 The Bigger Picture",
    "text": "6.11 The Bigger Picture\nThis approach transforms literature review from a bottleneck into an advantage. Instead of being limited to papers you can physically read, you can:\n\nCast a wider net across languages and disciplines\nIdentify patterns across large bodies of literature\nFocus your expertise on the most promising sources\nStay current with rapidly evolving fields\nEnable ambitious projects that require broad literature synthesis\n\nRemember: LLMs are your research assistants, not your replacements. They handle the volume so you can focus on insight, analysis, and critical judgment.\nThe goal isn’t to read less—it’s to read better. By using AI to filter and organize, you can spend more time on the deep, careful reading that produces real insights.\n\nUp next: Advanced Tools - NotebookLM and Deep Research",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Literature Review Enhancement: Widening Your Net</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html",
    "href": "apps_other_tools.html",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "",
    "text": "7.1 Learning Objectives\nTentative time: 12 minutes\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#learning-objectives",
    "href": "apps_other_tools.html#learning-objectives",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "",
    "text": "Understand RAG technology and how it enables analysis of large document collections\nUse NotebookLM effectively for multi-document analysis with proper citations\nLeverage Deep Research tools for comprehensive exploratory research\nRecognize the limitations of current AI research tools and plan accordingly\nIntegrate advanced tools into your research workflow strategically",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#why-these-tools-matter",
    "href": "apps_other_tools.html#why-these-tools-matter",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.2 Why These Tools Matter",
    "text": "7.2 Why These Tools Matter\nThe literature review techniques we just covered work well for individual papers or small sets of documents. But what about when you need to analyze patterns across dozens or hundreds of documents? Or when you want to do comprehensive exploratory research on a new topic?\nThis is where advanced AI tools become transformative. They’re not just faster—they enable entirely new kinds of research that were previously impossible for individual researchers or small teams.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#notebooklm-your-multi-document-research-assistant",
    "href": "apps_other_tools.html#notebooklm-your-multi-document-research-assistant",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.3 NotebookLM: Your Multi-Document Research Assistant",
    "text": "7.3 NotebookLM: Your Multi-Document Research Assistant\n\n7.3.1 What Is NotebookLM?\nNotebookLM is Google’s specialized tool for working with large document collections. Unlike regular chatbots that rely on their training data, NotebookLM creates a custom knowledge base from documents you upload.\nKey Capabilities:\n\nUpload up to 300 documents (PDFs, Word docs, web pages, etc.)\nAsk questions across your entire document collection\nGet answers with specific citations to source material\nClick citations to see the exact text that supports each claim\nCreate structured summaries of patterns across documents\n\n\n\n7.3.2 The Technology Behind It: RAG Explained\n\n\n\n\n\n\nWhat is RAG?\n\n\n\nRAG stands for “Retrieval Augmented Generation.” Here’s how it works in simple terms:\nStep 1: Document Chunking Your documents are broken into smaller chunks (usually a few paragraphs each).\nStep 2: Vector Mapping Each chunk is converted into a mathematical representation called a “vector” that captures its meaning. Think of this as creating a map where similar content clusters together.\nStep 3: Semantic Search When you ask a question, the system finds the chunks most relevant to your question by looking for similar vectors.\nStep 4: Context Assembly The most relevant chunks are assembled and fed to the LLM as context for generating your answer.\nStep 5: Citation Generation The system keeps track of which chunks came from which documents, enabling precise citations.\nWhy This Matters: Vector search finds content based on meaning, not just exact word matches. This is a huge advantage over traditional “Control + F” searching, which only finds specific phrases. The AI can find relevant passages even when different terminology is used.\nThis allows you to work with document collections far larger than any LLM’s context window while maintaining traceability to source material.\n\n\n\n\n7.3.3 Practical NotebookLM Workflow\nStep 1: Document Collection\nUpload your research materials:\n\nAcademic papers\nPolicy reports\nGovernment documents\nNews articles\nYour own notes and drafts\n\nStep 2: Initial Exploration\nStart with broad questions to understand your collection:\n\n“What are the main themes across these documents?”\n“Where do these authors disagree on key issues?”\n“What methodologies are being used to study this topic?”\n\nStep 3: Focused Analysis\nDive deeper into specific aspects:\n\n“How do different authors define [key concept]?”\n“What evidence is presented for [specific claim]?”\n“Which documents discuss [specific methodology]?”\n\nStep 4: Pattern Recognition\nLook for connections and gaps:\n\n“Are there any contradictions in findings across studies?”\n“What research questions remain unanswered?”\n“How has thinking on this topic evolved over time?”\n\nStep 5: Verification\nAlways click through citations to verify context and accuracy.\n\n\n7.3.4 Real-World Example: Chinese Development Finance\nIn our recent ODI research, we were trying to understand a shift in China’s overseas lending from policy banks to state-owned commercial banks. We analyzed the financial statements of the policy banks and wanted to complement this quantitative analysis with their own explanations via annual reports.\nHere’s what we uploaded to NotebookLM:\n\n10 years of China Development Bank and Export-Import Bank of China annual reports (containing text in both English and Mandarin - while we assume these are good translations, there might be subtle differences that are interesting)\n\nOur approach: We used NotebookLM for exploratory analysis rather than relying on its outputs directly. When our financial analysis revealed losses at China ExIM in 2017, we could easily ask how this was explained in the annual reports. We explored how both banks discussed key topics like green lending, risk management, and overseas lending losses.\n\n\n\nNotebookLM\n\n\nKey advantages:\n\nFaster than manual search: Dramatically quicker than “Control + F” searching across documents\nSemantic understanding: Vector search finds meaning, not just exact phrases\nCross-institutional analysis: Having reports from both institutions together helped us distinguish between institution-specific issues and broader policy changes\nMultilingual capability: The system could search in both English and Mandarin (my co-author speaks Mandarin, I do not)\n\nOur workflow:\n\nUpload all annual reports to NotebookLM\nAsk exploratory questions about patterns and changes over time\nUse NotebookLM results to identify which reports and sections to examine closely\nVerify findings by reading the original source material\nIncorporate insights into our broader financial analysis\n\nResults: NotebookLM pointed us toward the right primary sources rather than providing our final analysis. This saved enormous time while maintaining research integrity through verification against original documents.\n\n\n7.3.5 Best Practices for NotebookLM\nDocument Preparation:\n\nUse clear, descriptive file names\nInclude document metadata (author, date, type)\nConsider organizing by theme or time period\nRemove documents that aren’t directly relevant\n\nQuestioning Strategy:\n\nStart broad, then narrow down\nAsk follow-up questions based on initial results\nUse specific terminology from your field\nAsk for comparisons and contrasts\n\nCitation Verification:\n\nAlways click through citations to verify context\nCheck that quotes aren’t taken out of context\nVerify quantitative claims against source documents\nBe especially careful with technical or nuanced arguments",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#deep-research-tools-ai-powered-research-assistants",
    "href": "apps_other_tools.html#deep-research-tools-ai-powered-research-assistants",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.4 Deep Research Tools: AI-Powered Research Assistants",
    "text": "7.4 Deep Research Tools: AI-Powered Research Assistants\n\n7.4.1 What Are Deep Research Tools?\nDeep Research tools are AI systems that can conduct comprehensive research projects autonomously. You ask a question, and they spend 15-20 minutes researching the topic, then provide detailed reports that can be 15-30 pages long.\n\n\n\n\n\n\nUnderstanding AI Agents and Agentic Workflows\n\n\n\nDeep Research tools represent one of the first major successes in “agentic workflows” - AI systems that can pursue goals autonomously rather than just responding to single queries.\nWhat makes something “agentic”:\n\nGoal-oriented: Given a research question, the system formulates its own plan\nAutonomous execution: It conducts multiple searches and analysis steps without human guidance\nAdaptive behavior: It adjusts its approach based on what it finds\nTool use: It can access external resources and synthesize information from multiple sources\n\nWhy this matters: Traditional chatbots respond to individual prompts. Agents can tackle complex, multi-step projects that previously required human coordination and decision-making. Deep Research is one of the clearest examples of this capability working at a practical level.\nThe technology is evolving rapidly. As Ethan Mollick explains in “The End of Search, The Beginning of Research”, we’re seeing the convergence of “Reasoners” (AI that can think through problems step-by-step) and “Agents” (AI that can take autonomous action). This combination is creating new possibilities for research assistance.\n\n\nAvailable Tools:\n\nChatGPT Deep Research (OpenAI) - Currently produces the most sophisticated analysis\nClaude Research (Anthropic) - Newer tool with shorter outputs, still developing\nGemini Deep Research (Google) - Very long and detailed outputs, sometimes overwhelming\nPerplexity Pro - Uses DeepSeek’s R1 model, good middle ground between depth and accessibility\n\nNote: This landscape is changing rapidly. Tool capabilities and availability shift frequently.\n\n\n7.4.2 How Deep Research Works\nStep 1: Query Clarification The system often asks clarifying questions to understand what you’re really looking for.\nStep 2: Research Planning It creates a research plan with specific subtopics to investigate.\nStep 3: Systematic Search It conducts multiple searches across different sources and angles.\nStep 4: Synthesis It analyzes findings and creates a comprehensive report.\nStep 5: Fact-Checking It attempts to verify claims across multiple sources.\n\n\n7.4.3 Practical Example: Research Query\nQuestion: “What are the main barriers to renewable energy adoption in Sub-Saharan Africa, and what policy interventions have shown promise?”\nDeep Research Process:\n\nClarification: “Should I focus on specific technologies or countries?”\nResearch Plan: Infrastructure, financing, policy frameworks, case studies\nSystematic Search: Academic literature, policy reports, development bank analyses\nSynthesis: 20-page report with executive summary, detailed analysis, and recommendations\n\nTypical Output Quality:\n\nComprehensive coverage of major issues\nMultiple perspectives and sources\nQuantitative data where available\n\n\n\n7.4.4 Limitations and Caveats\nData Access Limitations:\n\nPrimarily accesses publicly available information\nLimited access to subscription academic databases\nMay miss recent developments or specialized sources\nRegional bias toward English-language sources\n\nQuality Variations:\n\nCan be confidently wrong about specific facts\nMay oversimplify complex issues\nSometimes misses important nuances\nCan struggle with rapidly evolving topics\n\nLicensing Issues:\n\nUnclear what content deals exist with publishers\nThis space is changing rapidly\nAcademic database access remains limited\nAlways verify claims against authoritative sources\n\n\n\n7.4.5 My Deep Research Workflow\nStep 1: Start with Known Topics Test the system’s performance on topics where you have expertise to calibrate the “jagged frontier.”\nStep 2: Use for Exploration Let it identify areas and sources you might not have considered.\nStep 3: Verify Key Claims Fact-check important assertions, especially quantitative ones.\nStep 4: Follow Up on Sources Use the research as a roadmap to find primary sources.\nStep 5: Integration Combine AI research with your domain expertise and additional sources.\n\n\n7.4.6 Realistic Expectations\nWhat I’ve Found Impressive:\n\nComprehensive coverage of complex topics\nSynthesis across multiple sources and perspectives\nIdentification of contradictions and debates\nQuality equivalent to what I’d expect from a skilled research assistant after a week of work\n\nWhat I’ve Found Concerning:\n\nOccasional confident assertions of false “facts”\nSometimes misses crucial recent developments\nCan perpetuate biases present in training data\nMay oversimplify politically sensitive issues\n\n\n\n7.4.7 Beyond Academic Research\nDeep Research tools aren’t just for scholarly work. I’ve found them helpful for many aspects of daily life that previously would have required a capable personal assistant or “chief of staff”:\n\nMeeting preparation: Understanding the backgrounds and expertise of people I’ll be meeting with (I used it to better understand the participants in this webinar!)\nTrip planning: Both professional and personal travel, from finding child-friendly attractions along road trip routes to understanding local customs and logistics\nPractical problem-solving: From figuring out how to stop woodpeckers from damaging my house to researching complex household decisions\nProfessional briefings: Getting up to speed on new sectors, regulations, or policy developments before important conversations\n\nThis represents a democratization of research capability that was previously available only to those with dedicated staff support.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#integrating-advanced-tools-into-your-workflow",
    "href": "apps_other_tools.html#integrating-advanced-tools-into-your-workflow",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.5 Integrating Advanced Tools into Your Workflow",
    "text": "7.5 Integrating Advanced Tools into Your Workflow\n\n7.5.1 The Strategic Approach\nUse NotebookLM when:\n\nYou have a collection of relevant documents\nYou need to find patterns across multiple sources\nYou want to verify claims against specific texts\nYou’re doing literature synthesis or comparative analysis\n\nUse Deep Research when:\n\nYou’re starting research on a new topic\nYou need broad coverage of an issue\nYou want to identify key debates and perspectives\nYou’re looking for policy examples or case studies\n\nAlways Remember:\n\nThese are tools for widening your net, not replacing judgment\nVerify important claims against authoritative sources\nUse your domain expertise to assess quality and relevance\nCombine AI research with traditional scholarly methods\n\n\n\n7.5.2 Building Your Advanced Research Workflow\nPhase 1: Exploration\n\nUse Deep Research for initial topic mapping\nUpload key documents to NotebookLM\nIdentify major themes and debates\n\nPhase 2: Analysis\n\nUse NotebookLM to analyze patterns across documents\nVerify key claims from Deep Research\nIdentify gaps and contradictions\n\nPhase 3: Synthesis\n\nCombine AI insights with your domain knowledge\nConduct focused searches for missing perspectives\nCreate your own analytical framework\n\nPhase 4: Verification\n\nFact-check quantitative claims\nVerify citations and sources\nEnsure balanced representation of viewpoints",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#hands-on-activity-advanced-research-project",
    "href": "apps_other_tools.html#hands-on-activity-advanced-research-project",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.6 Hands-On Activity: Advanced Research Project",
    "text": "7.6 Hands-On Activity: Advanced Research Project\nLet’s practice using these tools together:\nStep 1: Choose Your Research Question Select a topic you’re curious about but don’t know deeply.\nStep 2: Deep Research Phase Use a Deep Research tool to get broad coverage of your topic.\nStep 3: Document Collection Based on the Deep Research output, find 5-10 relevant documents to upload to NotebookLM.\nStep 4: Focused Analysis Use NotebookLM to dig deeper into specific aspects highlighted in the Deep Research.\nStep 5: Critical Assessment Evaluate the quality and consistency of insights across both tools.",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#what-you-can-do-now",
    "href": "apps_other_tools.html#what-you-can-do-now",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.7 What You Can Do Now",
    "text": "7.7 What You Can Do Now\n\nTest NotebookLM with a small collection of documents from your current research\nTry Deep Research on a topic you know well to calibrate its performance\nDevelop your verification workflow for checking AI-generated claims\nIdentify your research domains where these tools could be most valuable\nCreate your advanced research protocol combining both tools strategically",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  },
  {
    "objectID": "apps_other_tools.html#the-research-frontier",
    "href": "apps_other_tools.html#the-research-frontier",
    "title": "7  Advanced Tools: NotebookLM and Deep Research",
    "section": "7.8 The Research Frontier",
    "text": "7.8 The Research Frontier\nThese tools represent the current frontier of AI-assisted research. They’re not perfect, but they’re powerful enough to transform what’s possible for individual researchers and small teams.\nThe key is approaching them strategically:\n\nUse them to expand your scope, not replace your judgment\nVerify important claims through traditional scholarly methods\nCombine AI insights with your domain expertise\nStay critical and maintain academic standards\n\nAs these tools continue to evolve, researchers who learn to use them effectively will have significant advantages in conducting comprehensive, policy-relevant research.\n\nUp next: Coding Assistance and Data Analysis",
    "crumbs": [
      "Practical Applications",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Advanced Tools: NotebookLM and Deep Research</span>"
    ]
  }
]