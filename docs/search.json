[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "",
    "text": "Preface\nThis book accompanies the workshop AI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research for SOAS College of Social Sciences. In two hours, we‚Äôll explore how this new technology‚Äîdespite its limitations‚Äîcan enhance your research capabilities by handling routine tasks while you focus on critical analysis and theoretical contributions.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this workshop, you will be able to:\n\nEvaluate and select appropriate LLM tools for your research needs\nDesign effective prompts that leverage your domain expertise\nUse LLMs to enhance literature reviews and cross-disciplinary understanding\nApply LLMs for coding assistance and data analysis support\nUnderstand validation approaches for LLM-generated content\nRecognize both the transformative potential and important limitations of these tools",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#who-this-workshop-is-for",
    "href": "index.html#who-this-workshop-is-for",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Who This Workshop Is For",
    "text": "Who This Workshop Is For\nThis workshop is designed for experienced researchers who want to explore how LLMs might enhance their work. We assume you have:\n\nDeep expertise in your research domain\nHealthy skepticism about new technologies and their promises\nNo prior knowledge of LLMs or coding experience\nInterest in practical tools that could streamline routine research tasks\n\nYour skepticism is justified‚ÄîLLMs have real limitations we‚Äôll address directly. This workshop provides a realistic assessment of both capabilities and constraints.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#workshop-scope",
    "href": "index.html#workshop-scope",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Workshop Scope",
    "text": "Workshop Scope\nArtificial Intelligence is a vast and rapidly evolving field. In two hours, we can only cover a small portion of this landscape. This workshop aims to provide you with three core concepts that will equip you with immediately useful tools and a framework for continued learning:\n\nA mental model for understanding when and how to use AI effectively\nPractical techniques for common research tasks\nValidation strategies to maintain research integrity\n\n\nWhat We Will Cover\n\nConsumer-friendly LLM interfaces you can use immediately\nHands-on practice with real research applications\nIntroduction to programmatic possibilities for larger projects\nCase studies demonstrating successful academic use\n\n\n\nWhat We Will Not Cover\n\nComprehensive discussion of AI‚Äôs social implications (though we acknowledge them)\nDetailed API programming instruction\nExhaustive review of AI startup tools\nSolutions to replace human critical thinking",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#understanding-llms-in-research-context",
    "href": "index.html#understanding-llms-in-research-context",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Understanding LLMs in Research Context",
    "text": "Understanding LLMs in Research Context\nLarge Language Models represent a new category of research tool. Like any emerging technology, they come with significant limitations: training data biases, lack of contextual understanding, tendency to generate plausible-sounding but incorrect information, and important ethical considerations around consent and knowledge production.\nHowever, when used strategically and with appropriate validation, these tools can transform research workflows. By automating time-consuming routine tasks‚Äîinitial literature categorization, draft translations, basic coding‚ÄîLLMs free researchers to dedicate more time to what humans do best: critical analysis, theoretical development, contextual interpretation, and ethical judgment.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-your-instructor",
    "href": "index.html#about-your-instructor",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "About Your Instructor",
    "text": "About Your Instructor",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#our-two-hour-journey",
    "href": "index.html#our-two-hour-journey",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Our Two-Hour Journey",
    "text": "Our Two-Hour Journey\n\nPart 1: Foundations (20 minutes)\nUnderstanding LLMs as Research Tools\n\nThe ‚ÄúJagged Frontier‚Äù: Where AI excels versus where humans remain essential\nKey concepts: model capabilities, cost structures, context windows\nWhy Google Gemini for academic work (citations, extended context, NotebookLM)\n\n\n\nPart 2: Practical Applications (70 minutes)\nHands-On Tools and Techniques\n\nPrompt engineering fundamentals with practice exercises\nCreating reusable ‚ÄúGems‚Äù for common research tasks\nEnhancing literature reviews across languages and disciplines\nGetting coding assistance without programming expertise\nBrief exploration of complementary tools (Perplexity, ChatGPT, Claude)\n\n\n\nPart 3: Advanced Possibilities (15 minutes)\nScaling Your Research\n\nCase study: How I classified 18,000 Chinese overseas lending projects in 15 hours (versus 1,500 hours manually).\nValidation strategy: achieving 91.8% agreement with human raters\nEnabling policy-relevant analysis: quantifying green lending patterns across the Belt and Road Initiative\nIntroduction to programmatic approaches for large-scale research\nWhen and how to consider API-based workflows\n\n\n\nPart 4: Q&A and Discussion (15 minutes)\nYour Questions and Next Steps",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#approaching-this-material",
    "href": "index.html#approaching-this-material",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Approaching This Material",
    "text": "Approaching This Material\nThis workshop takes a pragmatic stance. We neither dismiss AI‚Äôs real limitations nor accept inflated claims about its capabilities. Instead, we focus on practical applications where LLMs demonstrably save time and enhance research capacity while maintaining academic standards.\nThroughout, we‚Äôll use clear language and define technical terms as they arise. When we discuss ‚Äúcontext windows,‚Äù we‚Äôll explain this means how much text an AI can process at once. When we mention ‚Äúhallucinations,‚Äù we‚Äôll clarify this refers to AI‚Äôs tendency to generate false but plausible information.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#preparing-for-the-workshop",
    "href": "index.html#preparing-for-the-workshop",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "Preparing for the Workshop",
    "text": "Preparing for the Workshop\nYou‚Äôll need:\n\nA free Google Gemini account (setup instructions in Appendix A)\nA research question or paper you‚Äôre currently working on\nWillingness to experiment while maintaining healthy skepticism",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "AI for the Sceptical Scholar: Practical Strategies for Using LLMs in Research",
    "section": "How to Use This Book",
    "text": "How to Use This Book\nEach chapter provides:\n\nClear explanation of concepts without unnecessary jargon\nStep-by-step instructions with visual guides\nHands-on exercises using real research scenarios\nCommon pitfalls and how to avoid them\nValidation strategies specific to each application\n\nThis book serves as both a workshop companion and a reference for future exploration. The goal is not to make you an AI expert but to provide practical tools that enhance your existing research practice.\nLet‚Äôs begin exploring how these tools can support your important work.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1¬† About Your Instructor",
    "section": "",
    "text": "1.1 How I Got Here\nCarlos Oya reached out after seeing a recent ODI Global paper I co-authored with Yunnan Chen called Greener on the other side? Mapping China‚Äôs overseas co-financing and financial innovation. We used a novel LLM-based approach to classify ‚Äúgreen‚Äù Chinese lending projects‚Äîsomething that would have taken a large research team months to do manually.\nWhen we did this work, I looked for ‚Äúbest practices‚Äù for validating LLM findings. There weren‚Äôt many. So we developed our own validation method and published both a methodological appendix and our GitHub repository. It‚Äôs not perfect, but it‚Äôs something for others to build upon.\nThis experience showed me how LLMs can enhance what‚Äôs possible for policy-relevant research. Two policy researchers on a tight budget accomplished what traditionally required large, grant-funded research teams. There‚Äôs a long way to go to establish best practices for the use of LLMs in policy research, so I‚Äôm trying to do my best to move the conversation forward.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#how-i-got-here",
    "href": "intro.html#how-i-got-here",
    "title": "1¬† About Your Instructor",
    "section": "",
    "text": "Source: Chen & Emery 2025\n\n\n\n\n\n\n\n\n\nKey Numbers from Our Chinese Lending Project\n\n\n\n\n18,000 projects classified in 15 hours using Deepseek v3\n$1.58 total cost vs.¬†estimated $22,500 for manual classification\n91.8% agreement with human raters on validation sample\nFirst comprehensive analysis of China‚Äôs green overseas lending portfolio",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#what-i-do-now",
    "href": "intro.html#what-i-do-now",
    "title": "1¬† About Your Instructor",
    "section": "1.2 What I Do Now",
    "text": "1.2 What I Do Now\nDay job: Running Teal Insights, where we help Global South finance ministries navigate complex debt sustainability and climate investment challenges. We‚Äôre philanthropically funded with a mandate to build open-source tools‚Äîincluding LLM tools‚Äîso countries don‚Äôt have to pay exorbitant fees to financial advisors.\nOur approach: Small team (US, Nigeria, Kenya) using AI tools heavily to amplify our impact in research and code development.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#other-relevant-experience",
    "href": "intro.html#other-relevant-experience",
    "title": "1¬† About Your Instructor",
    "section": "1.3 Other Relevant Experience",
    "text": "1.3 Other Relevant Experience\n\nEM sovereign debt resarch analyst, Morgan Stanley Investment Management\nAdjunct Lecturer, Johns Hopkins SAIS (teaching students to do real-world data analysis on financial and sustainability data)\n\nThought leadership on sovereign debt + sustainability, World Bank\nChinese debt restructuring & flows research, AidData\nBig nerd ü§ì",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "intro.html#why-this-workshop",
    "href": "intro.html#why-this-workshop",
    "title": "1¬† About Your Instructor",
    "section": "1.4 Why This Workshop?",
    "text": "1.4 Why This Workshop?\n\n\n\n\n\n\nA Note on Expertise\n\n\n\nThis technology is very new. Nobody is really an ‚Äúexpert‚Äù yet. But since we‚Äôre using these tools extensively, we‚Äôve learned hard lessons about how to use them well‚Äîand badly.\nWhen Carlos asked me to teach this, I figured it was a great excuse to organize my thoughts on something I discuss with skeptical, curious researchers all the time.\nThis is my first attempt at articulating practical guidance for academics who want to use AI responsibly. I hope it‚Äôs useful, and I invite all feedback on how to make it better.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>About Your Instructor</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html",
    "href": "foundations_intro.html",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "",
    "text": "2.1 Learning Objectives\nBy the end of this section, you will be able to:",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#learning-objectives",
    "href": "foundations_intro.html#learning-objectives",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "",
    "text": "Develop a mental model for understanding AI as a collaborative research tool rather than a replacement for human expertise\nUnderstand the ‚Äújagged frontier‚Äù concept and use it to predict where AI will excel versus where it will struggle\nTriage research tasks responsibly by categorizing them as human-only, collaborative, or AI-assisted based on the frontier\nRecognize AI‚Äôs key limitations (hallucination, bias, missing context) and plan accordingly\nBegin exploring your own jagged frontier through systematic experimentation with low-stakes tasks",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#why-this-matters-for-your-research",
    "href": "foundations_intro.html#why-this-matters-for-your-research",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.2 Why This Matters for Your Research",
    "text": "2.2 Why This Matters for Your Research\nBefore diving into the technical details, let‚Äôs be clear about why you might want to learn to work with AI: these tools can dramatically expand what‚Äôs possible for individual researchers and small teams. When used effectively, AI can handle routine tasks that typically consume enormous amounts of time‚Äîliterature searches, initial coding, translation, summarization‚Äîfreeing you to focus on what only you can do: critical analysis, theoretical development, fieldwork insights, and interpretation.\nThe researchers I know who‚Äôve learned to work well with AI aren‚Äôt replacing their expertise; they‚Äôre amplifying it. They‚Äôre tackling more ambitious projects, exploring research questions they previously couldn‚Äôt afford the time to pursue, and spending more of their energy on the intellectually rewarding aspects of research rather than the drudgery.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#a-new-way-to-think-about-ai-collaboration",
    "href": "foundations_intro.html#a-new-way-to-think-about-ai-collaboration",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.3 A New Way to Think About AI Collaboration",
    "text": "2.3 A New Way to Think About AI Collaboration\nThink of Large Language Models not as magical oracles or human replacements, but as sophisticated research assistants with a unique set of strengths and blind spots. Ethan Mollick suggests a particularly useful analogy:\n\ntreat AI like an infinitely patient new coworker who forgets everything you tell them each new conversation, one that comes highly recommended but whose actual abilities are not that clear.\n\nThis analogy helps us understand how to work with AI effectively:\nHuman-like aspects:\n\nNew on the job: Needs clear instructions and guidance, may not understand your specific context\nCoworker relationship: Works best through collaboration and back-and-forth dialogue\n\nNon-human aspects:\n\nInfinite patience: Never gets frustrated with repetitive requests or extensive revisions\nComplete forgetfulness: Starts fresh in each conversation with no memory of previous interactions\n\nUnlike traditional software that follows predictable rules, LLMs work more like collaborating with a capable but quirky colleague who can be creative and insightful, but may also confidently present plausible-sounding information that‚Äôs completely wrong.\n\n\n\n\n\n\nBuilding on Ethan Mollick‚Äôs Work\n\n\n\nThis chapter builds heavily on the work of Ethan Mollick, particularly his concept of the ‚Äújagged frontier‚Äù and his research on human-AI collaboration. I‚Äôve found his insights invaluable in my own journey learning to work with AI. I highly recommend reading his book Co-Intelligence and following his Substack ‚ÄúOne Useful Thing‚Äù for deeper insights into working effectively with AI.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#the-jagged-frontier-understanding-ais-uneven-capabilities",
    "href": "foundations_intro.html#the-jagged-frontier-understanding-ais-uneven-capabilities",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.4 The Jagged Frontier: Understanding AI‚Äôs Uneven Capabilities",
    "text": "2.4 The Jagged Frontier: Understanding AI‚Äôs Uneven Capabilities\nThe most important concept for working with LLMs is what Mollick (& esteemed co-authors) calls the ‚Äújagged frontier‚Äù of AI capabilities. Imagine a fortress wall with towers and battlements jutting out at irregular points. Some parts of the wall extend far into the countryside, while others fold back toward the center. This wall represents AI‚Äôs capabilities‚Äîeverything inside the wall represents tasks AI can handle well, while everything outside represents tasks where AI struggles.\n\n\n\nJagged Frontier of AI Capabilities\n\n\nThe challenge is that this wall is invisible. Tasks that seem equally difficult to humans often fall on opposite sides of the frontier. For example:\nInside the Frontier (AI excels):\n\nSummarizing academic papers and identifying key themes\nCreating first drafts of literature reviews\nTranslating research documents between major languages\nGenerating research questions and hypotheses to explore\nCoding assistance in most major languages (R, Python, STATA, etc..)\nWriting and formatting citations and bibliographies\n\nOutside the Frontier (AI struggles):\n\nGrasping context that isn‚Äôt explicitly stated\nMaking ethical judgments about research implications\nHumor. Seriously, try it. It‚Äôs all dad joke vibes\n\nThis unpredictability means you cannot assume that because AI handles one complex task well, it will handle a seemingly simpler related task with equal competence.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#what-llms-do-well-vs.-what-they-dont",
    "href": "foundations_intro.html#what-llms-do-well-vs.-what-they-dont",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.5 What LLMs Do Well vs.¬†What They Don‚Äôt",
    "text": "2.5 What LLMs Do Well vs.¬†What They Don‚Äôt\n\n2.5.1 AI Strengths\nScale and Speed: LLMs can process vast amounts of text in seconds. Need to identify key themes across 50 research papers? AI can help you get started in minutes rather than weeks.\nPattern Recognition: AI excels at identifying patterns across large datasets of text, finding connections you might miss, and synthesizing information from multiple sources.\nFirst-Draft Generation: Whether it‚Äôs grant applications, literature reviews, or research summaries, AI can create useful first drafts that you can then refine with your expertise.\nLanguage Tasks: Translation, summarization, and style adaptation are genuine AI strengths that can save researchers enormous amounts of time.\n\n\n2.5.2 AI Limitations\nHallucination: LLMs confidently generate plausible-sounding but false information. They might cite papers that don‚Äôt exist, create realistic-sounding statistics, or confidently state ‚Äúfacts‚Äù they‚Äôve essentially made up.\n\n\n\n\n\n\nWhat is Hallucination?\n\n\n\n‚ÄúHallucination‚Äù refers to when AI generates plausible-sounding but factually incorrect information. This isn‚Äôt a bug‚Äîit‚Äôs how these models work. They predict what text should come next based on patterns, not facts. A hallucinated research paper might have a realistic title, believable authors, and a publication year that makes sense, but the paper simply doesn‚Äôt exist.\n\n\nCultural and Geographic Bias: LLMs are trained predominantly on text from wealthy countries in the Global North, often in English. They reflect the biases in that data and may default to Western-centric perspectives on development, governance, or social issues.\nMissing Context: AI only knows what‚Äôs explicitly written down. It misses the unspoken context that you understand from fieldwork‚Äîthe power dynamics in a room, historical tensions between communities, or the significance of what isn‚Äôt being said.\nLack of True Understanding: When I read IMF documents, boring bureaucratic language often hides spicy geopolitical tensions that you can detect if you understand the context. AI reads the words but misses the subtext entirely.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#the-collaborative-model-you-provide-expertise-ai-provides-scale",
    "href": "foundations_intro.html#the-collaborative-model-you-provide-expertise-ai-provides-scale",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.6 The Collaborative Model: You Provide Expertise, AI Provides Scale",
    "text": "2.6 The Collaborative Model: You Provide Expertise, AI Provides Scale\nThe most effective approach treats AI as a collaborator rather than a replacement. Here‚Äôs how to think about the division of labor:\nYour Unique Value:\n\nDomain expertise and contextual understanding\nCritical analysis and theoretical frameworks\nEthical judgment and interpretation\nUnderstanding of implicit meanings and power dynamics\nAbility to validate and verify AI outputs\n\nAI‚Äôs Unique Value:\n\nProcessing large volumes of text quickly\nIdentifying patterns across many documents\nGenerating first drafts and creative alternatives\nHandling routine, time-consuming tasks\nProviding different perspectives to consider",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#triaging-tasks-along-the-frontier",
    "href": "foundations_intro.html#triaging-tasks-along-the-frontier",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.7 Triaging Tasks Along the Frontier",
    "text": "2.7 Triaging Tasks Along the Frontier\nUse the jagged frontier concept to categorize your research tasks:\n\n2.7.1 Human-Only Tasks\nTasks where AI is unreliable or where human judgment is essential:\n\nFinal interpretation of sensitive field data\nEthical analysis of research implications\nUnderstanding implicit cultural dynamics\nMaking final decisions about research direction\n\n\n\n2.7.2 Collaborative Tasks (Near the Frontier)\nTasks where AI can help but requires careful human oversight:\n\nLiterature reviews (AI helps find patterns, you verify and interpret)\nData analysis (AI helps with initial coding, you validate themes)\nCross-language work (AI provides translations, you check accuracy)\nGrant writing (AI creates drafts, you ensure accuracy and voice)\n\n\n\n2.7.3 AI-Assisted Tasks (Inside the Frontier)\nTasks you can safely delegate with light oversight:\n\nFirst-pass summarization of documents\nFormatting and citation cleanup\nTranslation of straightforward technical content\nCreating multiple versions of the same content for different audiences",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#finding-your-own-jagged-frontier",
    "href": "foundations_intro.html#finding-your-own-jagged-frontier",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.8 Finding Your Own Jagged Frontier",
    "text": "2.8 Finding Your Own Jagged Frontier\nThe jagged frontier varies between individuals, research domains, and even specific projects. You need to discover it yourself through experimentation. Here‚Äôs how:\nStart with your own work: Begin by testing AI on your own papers and research. You‚Äôll quickly spot when it gets things wrong because you know the material intimately.\nBegin with low-stakes tasks: Try AI first on tasks where errors won‚Äôt matter much‚Äîreformatting text, creating bullet point summaries, or generating initial ideas.\nTest systematically: When you find a task AI handles well, try similar but slightly different tasks to map the boundaries of its capabilities.\nStay updated: The frontier is expanding rapidly but unevenly. AI that was terrible at math six months ago may now be excellent due to integrated calculation tools. Assume the AI you‚Äôre working with today is the worst AI you‚Äôll ever use.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  },
  {
    "objectID": "foundations_intro.html#key-principles-for-success",
    "href": "foundations_intro.html#key-principles-for-success",
    "title": "2¬† Understanding LLMs as Collaborative Research Assistants",
    "section": "2.9 Key Principles for Success",
    "text": "2.9 Key Principles for Success\n\nAlways verify: Never trust AI output without checking, especially for facts, citations, or quantitative claims.\nUse your expertise: Work with AI on topics where you have deep knowledge so you can catch errors and guide the process effectively.\nEmbrace iteration: AI works best through conversation and refinement, not one-shot requests.\nMaintain critical thinking: AI should amplify your analytical capabilities, not replace them.\nDocument your discoveries: Keep track of what works and what doesn‚Äôt for your specific research context.\n\nThe goal isn‚Äôt to become an AI expert‚Äîit‚Äôs to become more effective at research by understanding how to collaborate with these powerful but imperfect tools. In the next section, we‚Äôll explore the practical considerations of choosing and using specific AI systems for academic work.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Understanding LLMs as Collaborative Research Assistants</span>"
    ]
  }
]